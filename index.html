<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>GPU 观察</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="GPU 观察">
<meta property="og:url" content="https:&#x2F;&#x2F;gpuinsight.com&#x2F;index.html">
<meta property="og:site_name" content="GPU 观察">
<meta property="og:locale" content="cn">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="GPU 观察" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">GPU 观察</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://gpuinsight.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-rendering_pipeline" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/30/rendering_pipeline/" class="article-date">
  <time datetime="2019-12-30T00:00:00.000Z" itemprop="datePublished">2019-12-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/30/rendering_pipeline/">图形渲染管线</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过阅读本文，你将知道：</p>
<ol>
<li>图形渲染的基本过程是怎样的？</li>
<li>计算机图形学视角下的图形渲染管线是怎样的？</li>
<li>OpenGL视角下的图形渲染管线是怎样的？</li>
<li>GPU芯片设计者视角下的图形渲染管线是怎样的？</li>
</ol>
<h1 id="图形渲染过程"><a href="#图形渲染过程" class="headerlink" title="图形渲染过程"></a>图形渲染过程</h1><p>图形渲染过程可以类比于给模特拍照的过程。</p>
<img src="/2019/12/30/rendering_pipeline/1.jpg" class="" title="Lina">

<p>首先我们需要选择一个模特，给模特化妆，选择合适的首饰服装。然后将各种物品以及模特安排在场景的合适位置。接着摄影师调整灯光亮度，设置好相机的各种参数（角度，曝光度等）。最后按下快门，经过打印之后一张图片就生成了。</p>
<p>总结下一张图片的生成过程，大致可以分为四步，分别为：</p>
<ol>
<li>建模</li>
<li>场景构建</li>
<li>视景体选择</li>
<li>绘制</li>
</ol>
<p><strong>第一步 建模</strong></p>
<p>建模是构建模型的过程。在上述场景中模特以及模特周围的物品都可以看成一个个的模型，选择模特、装扮模特、选择物品都属于建模的过程。</p>
<p><strong>第二步 场景构建</strong></p>
<p>场景构建是搭建我们要渲染的整个场景的过程。包含将各个模型放置在合适的位置以及设置好场景的全局属性（如光照、背景色等）。</p>
<p><strong>第三步 视景体选择</strong></p>
<p>视景体选择是选择场景展现范围和效果的过程。相机的不同位置、不同角度影响场景的展现范围；相机参数的设置影响场景的展现效果。</p>
<p><strong>第四步 绘制</strong></p>
<p>绘制是将图像最终展现到我们眼前的过程。虽然我们已经按下快门，选择了要展现的场景，但是由于打印颜色种类和质量的限制、打印机的设置或者洗照片的化学药剂的成分设置、纸张的长宽比和大小的不同，最终我们看到的图形也会千差万别。</p>
<h1 id="计算机图形渲染"><a href="#计算机图形渲染" class="headerlink" title="计算机图形渲染"></a>计算机图形渲染</h1><p>计算机图形是用计算机产生的图像。</p>
<p>在给模特拍照的例子中，人、物、场景都是现实中已经存在的，而在计算机图形渲染过程中，他们都需要计算机自己构建。</p>
<p>那怎样用计算机高效地渲染出真实图形呢？计算机图形学应运而生！</p>
<p>计算机图形学就是研究如何在计算机中表示图形，以及利用计算机进行图形的计算、处理和显示的相关原理和算法。</p>
<blockquote>
<p>Computer Graphics is the art of science of producing graphical images with the aid of computer. - IEEE</p>
</blockquote>
<p>计算机在图形渲染方面有其局限性。相对于图形渲染过程中的海量数据处理，计算机的计算能力是有限的；计算机图形显示设备是以离散形式显示图形的，比如分辨率为1080p的显示器，其包含的是1920x1080个像素点；计算机的计算精度有限等等。</p>
<p>由此便衍生出来很多优化算法，如：纹理、背面消隐、提前的深度模板测试等。</p>
<p>另外由于人眼的视觉特性，计算机也可以适当偷点懒。如帧率只需要达到34帧/秒，人眼便没有了卡顿感（游戏画面要求达到60帧/秒）；人眼对运动中的画面的细节感知能力很低等。</p>
<p>纹理是最常用的优化措施。例如渲染一个游戏场景中的一棵树，与其使用成千上万个顶点构建这颗树的模型，不如直接使用一张纹理图片来代替。这样做可以极大的提高渲染效率。</p>
<p>从上述可知，计算机图形渲染的输入有两类，分别为：顶点输入和像素输入；计算机图形渲染的输出为：帧缓冲区中的图像。</p>
<p>帧缓冲区中的图像像素会由显示控制器以固有的频率读到显示器上进行显示。</p>
<img src="/2019/12/30/rendering_pipeline/2.png" class="" title="计算机图形渲染管线的输入和输出">

<p>计算机图形渲染分为实时渲染和非实时渲染。所谓实时，即快速响应。通常游戏画面的渲染都是实时渲染，计算机制作的电影画面的渲染都是非实时渲染。一个大型游戏的任何时刻截一张图都非常清晰，而电影画面中的高速运动物体的截图则是模糊的。</p>
<p>计算机图形学中并没有明确地定义图形渲染管线，其更多的是研究如何使用计算机更快更好的渲染图形，多偏向于算法方向。图形渲染管线将在后续章节以OpenGL为例进行讲解。</p>
<h1 id="OpenGL渲染管线"><a href="#OpenGL渲染管线" class="headerlink" title="OpenGL渲染管线"></a>OpenGL渲染管线</h1><p>渲染管线可分为可编程渲染管线和固定功能渲染管线。详细介绍请参看《GPU的渲染架构、渲染管线和渲染模式分类》<br>)</p>
<p>关于<code>OpenGL渲染管线</code>，我们可以在各种地方看到这个关键词：计算机图形学、OpenGL官方网站、各大GPU厂商的官网等等。你会发现他们说的都不太一样。</p>
<h2 id="计算机图形学视角看OpenGL渲染管线"><a href="#计算机图形学视角看OpenGL渲染管线" class="headerlink" title="计算机图形学视角看OpenGL渲染管线"></a>计算机图形学视角看OpenGL渲染管线</h2><p>OpenGL最初的内部流程是一组有序的处理步骤，这些步骤被组织为一个双通道的渲染流水线。流水线阶段当然是固定的—也就是说，它们无论接受到什么样的输入数据都会执行特定的操作—因此，这样的工作方式成为固定功能的OpenGL流水线。</p>
<img src="/2019/12/30/rendering_pipeline/3.png" class="" title="计算机图形学视角下的OpenGL固定功能渲染管线">

<p>图中，黑色方框部分一般称为<strong>几何流水线</strong>，Geometry Pipeline；橘色方框部分一般称为<strong>像素流水线</strong>，Pixel Pipeline。</p>
<img src="/2019/12/30/rendering_pipeline/4.png" class="" title="计算机图形学视角下的OpenGL可编程渲染管线">

<p>图中，绿色方框部分是可编程的。应用程序通过使用Shader来控制这些阶段内所进行的操作。Shader指的是一些比较短的程序段，它们被加载到OpenGL程序中，并最终加入到OpenGL流水线的适当的处理单元中，替换掉流水线中原来的固定功能。</p>
<h2 id="程序员视角看OpenGL渲染管线"><a href="#程序员视角看OpenGL渲染管线" class="headerlink" title="程序员视角看OpenGL渲染管线"></a>程序员视角看OpenGL渲染管线</h2><p>使用OpenGL编写应用程序或渲染引擎的程序员所面对的是OpenGL标准API。</p>
<p>在介绍OpenGL标准API展示的渲染管线之前，我们先了解一下OpenGL中的坐标表示。</p>
<h3 id="OpenGL坐标系"><a href="#OpenGL坐标系" class="headerlink" title="OpenGL坐标系"></a>OpenGL坐标系</h3><p>常见的坐标系有：</p>
<ul>
<li>建模坐标系。盒子是什么形状</li>
<li>世界坐标系。把盒子放在整个场景中的哪个位置</li>
<li>观察和投影坐标系。从哪个角度位置看这个盒子</li>
<li>规范化设备坐标系。指定为一个设备无关的坐标系</li>
<li>设备坐标系。将最终的图形显示到什么样的设备上</li>
</ul>
<img src="/2019/12/30/rendering_pipeline/5.png" class="" title="坐标变换">

<h3 id="OpenGL渲染管线-1"><a href="#OpenGL渲染管线-1" class="headerlink" title="OpenGL渲染管线"></a>OpenGL渲染管线</h3><p>OpenGL官方WIKI上将渲染管线分为7个步骤，分别为：</p>
<ol>
<li>Vertex Specification：指定顶点数据</li>
<li>Vertex Processing：顶点处理</li>
<li>Vertex Post-Processing：顶点后处理</li>
<li>Primitive Assembly：图元装配</li>
<li>Rasterization：光栅化</li>
<li>Fragment Shader：片段着色</li>
<li>Per-Sample Processing ：逐样本处理</li>
</ol>
<img src="/2019/12/30/rendering_pipeline/6.png" class="" title="OpenGL渲染管线">

<img src="/2019/12/30/rendering_pipeline/7.png" class="" title="OpenGL渲染管线">

<h2 id="GPU设计厂商视角看OpenGL渲染管线"><a href="#GPU设计厂商视角看OpenGL渲染管线" class="headerlink" title="GPU设计厂商视角看OpenGL渲染管线"></a>GPU设计厂商视角看OpenGL渲染管线</h2><p>和程序员一样，GPU设计厂商面对的也是OpenGL标准API，不同的是，前者是如何使用它们，后者是如何实现它们。</p>
<p>在考虑如何实现他们之前，得先考虑该GPU是应用在什么场景。桌面端的GPU更注重性能，而功耗和面积则非重点考虑因素；移动端的GPU更注重功耗和面积，性能相较于桌面端的GPU则不那么高…</p>
<p>总而言之，GPU设计者需要根据应用场景在功耗、性能和面积组成的三角形中选择一个“完美”的点作为“质心”。</p>
<h3 id="驱动程序"><a href="#驱动程序" class="headerlink" title="驱动程序"></a>驱动程序</h3><p>GPU设计厂商提供给用户的除了GPU显卡之外，还有驱动程序。驱动程序运行在CPU上。</p>
<p>通常，驱动程序会对OpenGL API进行预处理。OpenGL API会被逐个放到命令缓冲区（软件概念），当遇到一个Draw Terminator做特定处理，当遇到一个Frame Terminator做特定处理。</p>
<p>Draw Terminator通常是:</p>
<ol>
<li>glDrawArrays系列</li>
<li>glDrawElements系列</li>
<li>glBegin</li>
</ol>
<p>Frame Terminator通常是:</p>
<ol>
<li>glClear</li>
<li>glFlush</li>
<li>glFinish</li>
<li>SwapBuffers</li>
<li>glXMakeCurrent/glXMakeContextCurrent</li>
<li>SwapLayerBuffers</li>
<li>glFrameTerminatorGREMEDY</li>
</ol>
<p>这里顺便提一下OpenCL中的Frame Terminator：</p>
<ol>
<li>clFlush</li>
<li>clFinish</li>
<li>clWaitForEvents</li>
<li>cl_gremedy_computation_frame</li>
</ol>
<p>上述的“特定处理”，不同的GPU是完全不一样的。但他们的核心目的都是将OpenGL API转换成GPU硬件认识的，可以让GPU硬件高效工作的指令和数据。</p>
<h3 id="GPU硬件渲染管线"><a href="#GPU硬件渲染管线" class="headerlink" title="GPU硬件渲染管线"></a>GPU硬件渲染管线</h3><img src="/2019/12/30/rendering_pipeline/8.png" class="" title="GeForce6800">

<p>上图是GeForce6800的硬件架构图。其处理流程为：从主机接收到驱动程序发送的指令和数据，先进行顶点着色。然后着色后的顶点进行图元装配，再对图元进行背面消隐、剪裁和光栅化。光栅化产生的片段送到片段着色器进行片段着色，此过程中有可能会用到纹理。着色后的片段再送到ROP单元进行深度模板测试、混合等操作，最后将像素写回帧缓冲区。</p>
<p>上述过程看着和OpenGL官网描述的渲染管线挺像的。其实不然。上图中“ZCull”模块可以提前进行深度模板测试。</p>
<p>理论上，我们甚至可以在OpenGL API和GPU硬件之间再做一层封装，使得GPU硬件和OpenGL描述的渲染管线的逻辑模型的关联很小。随着GPU架构的发展，GPU硬件和OpenGL描述的渲染管线的逻辑模型的关联也确实越来越小。</p>
<p>尝试设计过GPU的人，应该遇到过显示列表这个“坑”。站在程序员角度，显示列表这个特性无可厚非，把一堆OpenGL API放在GPU，方便随时调用。但是GPU设计者要实现这个功能时非常痛苦。</p>
<p>Khronos Group在2015年游戏开发者大会上推出了Vulkan。相对于 OpenGL，Vulkan™ 大幅降低了 CPU 在提供重要特性、性能和影像质量时的“API 开销”，而且可以使用通常通过 OpenGL 无法访问的 GPU 硬件特性。</p>
<p>由此可见，Khronos Group在API设计上，也是对GPU设计者越来越友好。或者说，Khronos Group中有越来越多的GPU设计者参与进来。应用程序开发者的学习成本会略微增加。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>计算机图形学视角看OpenGL渲染管线，是算法模型；程序员视角看OpenGL渲染管线，是逻辑模型；GPU设计厂商视角看OpenGL渲染管线，是硬件（架构）模型。</li>
<li>图形渲染管线可以分为顶点获取、顶点处理、图元生成、图元处理、片段生成、片段处理共六个阶段。</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.lenna.org" target="_blank" rel="noopener">Lena的故事</a></li>
<li><a href="https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview" target="_blank" rel="noopener">https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview</a></li>
<li><a href="https://gpuopen.com/compute-product/codexl/" target="_blank" rel="noopener">https://gpuopen.com/compute-product/codexl/</a></li>
<li>《Realtime Rendering》第四版</li>
<li><a href="https://baike.baidu.com/item/Vulkan/17543632?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/Vulkan/17543632?fr=aladdin</a></li>
<li>《计算机图形学》第四章</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/12/30/rendering_pipeline/" data-id="ck63782nu001b09ww8o4o3zga" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BE%E5%BD%A2%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">图形渲染管线</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpu_vs_cpu" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/29/gpu_vs_cpu/" class="article-date">
  <time datetime="2019-12-29T00:00:00.000Z" itemprop="datePublished">2019-12-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/29/gpu_vs_cpu/">CPU和GPU的区别</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过阅读本文你可以知道CPU和GPU的区别是什么。</p>
<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><img src="/2019/12/29/gpu_vs_cpu/1.png" class="" title="CPU与GPU的结构">

<p>上图是CPU和GPU的结构对比图。通过对比可以看出：</p>
<ol>
<li>CPU的计算单元较复杂，但是个数较少；GPU的计算单元相对简单，但是个数很多</li>
<li>CPU的控制单元较复杂；GPU的控制单元相对简单，分布在各计算核</li>
<li>CPU的片上缓存较大；GPU的片上缓存较小，分布在各计算核</li>
</ol>
<p>为何他们的结构会差别这么大？这还得从他们的设计目标说起。</p>
<h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><p>我们知道，GPU最开始是专门用来做图像渲染的。图像渲染有以下特点：</p>
<ol>
<li>被渲染的场景由非常多的顶点组成</li>
<li>顶点组成的场景会被光栅化成非常多的片段</li>
<li>对每个顶点或片段的处理逻辑都是一样的</li>
</ol>
<p>这类数据可以称作流数据。流数据具有数据量大和每个数据分量的处理逻辑类似的特点。NVIDIA的GPU中有一个概念是Stream Processor，即流处理器。流处理器处理的数据即为流数据。</p>
<p>所以，GPU的设计目标是提高数据吞吐量。</p>
<p>CPU要处理的任务从一开始就特别复杂，它得保证具有复杂控制逻辑的程序快速运行，而且还得支持多任务。多任务要求CPU的运行频率较高，这样才能让用户感觉多个任务是在并发执行。</p>
<p>所以，GPU的设计目标是低时延。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>CPU需要很强的通用性来处理各种不同的数据类型，同时又要逻辑判断又会引入大量的分支跳转和中断的处理。这些都使得CPU的内部结构异常复杂。而GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。</li>
<li>CPU是几个教授组成的，而GPU是很多个小学生组成的。</li>
<li>CPU采用基于低延时的设计；GPU采用基于高吞吐量的设计。</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/biglucky/p/4223565.html" target="_blank" rel="noopener">https://www.cnblogs.com/biglucky/p/4223565.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/12/29/gpu_vs_cpu/" data-id="ck63782n9000g09wwavjg16s3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CPU/" rel="tag">CPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-vulkan_study_plan" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/28/vulkan_study_plan/" class="article-date">
  <time datetime="2019-12-28T00:00:00.000Z" itemprop="datePublished">2019-12-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/28/vulkan_study_plan/">Vulkan学习计划</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文记录的是个人的Vulkan学习计划，仅供参考。</p>
<p>制定Vulkan学习计划的思路是：</p>
<ol>
<li>找学习资料</li>
<li>根据学习资料掌握Vulkan整体脉络</li>
<li>根据整体脉络制定学习计划</li>
<li>执行学习计划</li>
</ol>
<p>找学习资料有一个原则：找第一手资料或权威的资料。这是为了避免走弯路。</p>
<h1 id="资料整理"><a href="#资料整理" class="headerlink" title="资料整理"></a>资料整理</h1><h2 id="官网"><a href="#官网" class="headerlink" title="官网"></a>官网</h2><ol>
<li><p>官网：<a href="https://www.khronos.org/vulkan/" target="_blank" rel="noopener">https://www.khronos.org/vulkan/</a></p>
</li>
<li><p>说明文档主页：<a href="https://www.khronos.org/registry/vulkan/" target="_blank" rel="noopener">https://www.khronos.org/registry/vulkan/</a></p>
<ol>
<li>说明文档：<a href="https://www.khronos.org/registry/vulkan/specs/" target="_blank" rel="noopener">https://www.khronos.org/registry/vulkan/specs/</a><ul>
<li>v1.0：<a href="https://www.khronos.org/registry/vulkan/specs/1.0/html/" target="_blank" rel="noopener">https://www.khronos.org/registry/vulkan/specs/1.0/html/</a></li>
<li>v1.1：<a href="https://www.khronos.org/registry/vulkan/specs/1.1/html/" target="_blank" rel="noopener">https://www.khronos.org/registry/vulkan/specs/1.1/html/</a></li>
</ul>
</li>
</ol>
</li>
<li><p>示例程序：<a href="https://github.com/KhronosGroup/Vulkan-Samples" target="_blank" rel="noopener">https://github.com/KhronosGroup/Vulkan-Samples</a></p>
</li>
<li><p>学习指引：<a href="https://github.com/KhronosGroup/Vulkan-Guide" target="_blank" rel="noopener">https://github.com/KhronosGroup/Vulkan-Guide</a></p>
</li>
</ol>
<h2 id="NVIDIA"><a href="#NVIDIA" class="headerlink" title="NVIDIA"></a>NVIDIA</h2><ol>
<li>NVIDIA Vulkan：<a href="https://developer.nvidia.com/Vulkan" target="_blank" rel="noopener">https://developer.nvidia.com/Vulkan</a></li>
<li>培训资料：<a href="https://developer.nvidia.com/nvidia-vulkan-developer-day" target="_blank" rel="noopener">https://developer.nvidia.com/nvidia-vulkan-developer-day</a><ul>
<li>Vulkan整体介绍：<a href="https://developer.nvidia.com/sites/default/files/akamai/gameworks/VulkanDevDaypdaniel.pdf" target="_blank" rel="noopener">VulkanDevDaypdaniel.pdf</a></li>
</ul>
</li>
</ol>
<h2 id="AMD"><a href="#AMD" class="headerlink" title="AMD"></a>AMD</h2><ol>
<li>AMD Vulkan：<a href="https://www.amd.com/zh-hans/technologies/vulkan" target="_blank" rel="noopener">https://www.amd.com/zh-hans/technologies/vulkan</a></li>
</ol>
<h2 id="IMAGINATION"><a href="#IMAGINATION" class="headerlink" title="IMAGINATION"></a>IMAGINATION</h2><ol>
<li>IMAGINATION Vulkan：<a href="https://www.imgtec.com/developers/vulkan/" target="_blank" rel="noopener">https://www.imgtec.com/developers/vulkan/</a></li>
</ol>
<h2 id="Qualcomm"><a href="#Qualcomm" class="headerlink" title="Qualcomm"></a>Qualcomm</h2><ol>
<li>高通 Vulkan：<a href="https://developer.qualcomm.com/qfile/34706/80-nb295-7_a-adreno_vulkan_developer_guide.pdf" target="_blank" rel="noopener">Qualcomm Adreno Vulkan - Qualcomm Developer Network</a></li>
<li><a href="https://developer.qualcomm.com/blog/how-start-using-adreno-sdk-vulkan" target="_blank" rel="noopener">How to Start Using Adreno SDK for Vulkan</a></li>
</ol>
<h2 id="ARM"><a href="#ARM" class="headerlink" title="ARM"></a>ARM</h2><ol>
<li>ARM Vulkan：<a href="https://developer.arm.com/solutions/graphics/apis/vulkan" target="_blank" rel="noopener">https://developer.arm.com/solutions/graphics/apis/vulkan</a></li>
</ol>
<h1 id="学习计划"><a href="#学习计划" class="headerlink" title="学习计划"></a>学习计划</h1><p>待添加</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/12/28/vulkan_study_plan/" data-id="ck63782nc000j09ww6www8cvj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Vulkan/" rel="tag">Vulkan</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpu_performance" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/26/gpu_performance/" class="article-date">
  <time datetime="2019-12-26T00:00:00.000Z" itemprop="datePublished">2019-12-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/26/gpu_performance/">GPU性能指标</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过阅读本文，你将知道GPU的性能指标都有哪些以及他们是如何计算出来的。</p>
<h1 id="GPU性能指标"><a href="#GPU性能指标" class="headerlink" title="GPU性能指标"></a>GPU性能指标</h1><p>在GPU信息数据库-GPU Specs Database，可以查找到几乎所有GPU的信息。GPU信息中有一栏代表的是GPU的性能参数：Theoretical Performance。</p>
<p>通过阅读这一栏数据我们可以知道：</p>
<ol>
<li>这些数据都是<strong>理论上的峰值</strong></li>
<li>性能指标一般有：<strong>纹理填充率</strong>、<strong>像素填充率</strong>和<strong>浮点处理能力</strong></li>
</ol>
<h2 id="理论上的峰值"><a href="#理论上的峰值" class="headerlink" title="理论上的峰值"></a>理论上的峰值</h2><p>所谓理论上的峰值可以理解为理想情况下的峰值，GPU在实际运行过程中几乎都跑不出该峰值。</p>
<p>在得出这个理论上的峰值的过程中，做了很多假设。</p>
<p><strong>假设一，一个时钟完成一次处理。</strong>如：一个时钟完成一个像素的渲染，实际上一个时钟是完不成一个像素的渲染任务的，反而根据我们写的片段染色程序的复杂度，可能需要上百甚至更多的时钟。</p>
<p><strong>假设二，数据已准备好。</strong>如：像素渲染的输入数据总是可以立马获取到，实际并非如此。</p>
<p><strong>假设三，任务调度和逻辑控制不消耗时钟。</strong></p>
<p>至于这个理论上的峰值是如何计算得来的，请参看下面章节的介绍。</p>
<h2 id="纹理填充率"><a href="#纹理填充率" class="headerlink" title="纹理填充率"></a>纹理填充率</h2><blockquote>
<p>纹理填充率 = 纹理单元运行的时钟频率 x 纹理单元的个数 x 每个时钟纹理单元可以处理的纹素个数（理论值）</p>
</blockquote>
<p>比如NAVIDA的<a href="https://www.techpowerup.com/gpu-specs/geforce-gt-430.c603" target="_blank" rel="noopener">GeForce GT 430</a>：</p>
<ul>
<li>纹理单元运行的时钟频率为：700 MHz</li>
<li>纹理单元的个数：16个</li>
<li>每个时钟纹理单元可以处理的纹素个数：1个</li>
</ul>
<p>所以它的纹理填充率为11.20 GTexel/s。</p>
<h2 id="像素填充率"><a href="#像素填充率" class="headerlink" title="像素填充率"></a>像素填充率</h2><blockquote>
<p>像素填充率 = ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数</p>
</blockquote>
<p>比如NAVIDA的<a href="https://www.techpowerup.com/gpu-specs/geforce-gt-430.c603" target="_blank" rel="noopener">GeForce GT 430</a>：</p>
<ul>
<li>ROP运行的时钟频率：700 MHz</li>
<li>ROP的个数：4个</li>
<li>每个时钟ROP可以处理的像素个数：1个</li>
</ul>
<p>所以它的像素填充率为2.800 GPixel/s</p>
<h2 id="浮点处理能力"><a href="#浮点处理能力" class="headerlink" title="浮点处理能力"></a>浮点处理能力</h2><p>浮点处理包含半精度、单精度和双精度浮点的处理。</p>
<p>下面以单精度浮点处理能力为例：</p>
<blockquote>
<p>单精度浮点处理能力 = 渲染核运行的时钟频率 x 渲染核的个数 x 每个渲染核包含的单精度浮点处理单元的个数</p>
</blockquote>
<p>比如NAVIDA的<a href="https://www.techpowerup.com/gpu-specs/geforce-gt-430.c603" target="_blank" rel="noopener">GeForce GT 430</a>：</p>
<ul>
<li>渲染核运行的时钟频率：1400 MHz</li>
<li>渲染核的个数：96个</li>
<li>每个渲染核包含的单精度浮点处理单元的个数：2个（这个数值是逆推出来的，原网页没有该信息）</li>
</ul>
<p>所以它的单精度浮点处理能力为268.8 GFLOPS</p>
<p>注意：每个渲染核包含的单精度浮点处理单元的个数是逆推出来的。在本例中逆推出来是2，实际上还有可能是1，因为如果该单精度浮点处理单元支持乘加操作的话，一个浮点乘法和一个浮点加法，是两个浮点操作。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>GPU的性能指标包含：纹理填充率、像素填充率和浮点处理能力</li>
<li>纹理填充率的计算方式为：纹理单元运行的时钟频率 x 纹理单元的个数 x 每个时钟纹理单元可以处理的纹素个数（理论值）</li>
<li>像素填充率的计算方式为：ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数</li>
<li>单精度浮点处理能力的计算方式为：渲染核运行的时钟频率 x 渲染核的个数 x 每个渲染核包含的单精度浮点处理单元的个数</li>
<li>GPU性能指标的数值都是理论值</li>
<li>知道了GPU性能指标的计算方式，我们可以从GPU厂商公布的数据中逆推得到一些有用的信息</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.gpuzoo.com/" target="_blank" rel="noopener">GPUZoo</a></li>
<li><a href="https://www.techpowerup.com/gpu-specs/" target="_blank" rel="noopener">GPU Specs Database</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/12/26/gpu_performance/" data-id="ck63782n7000c09wwfu3i74m9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpu_terms" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/gpu_terms/" class="article-date">
  <time datetime="2019-12-23T00:00:00.000Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/gpu_terms/">GPU的渲染架构、渲染管线和渲染模式分类</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过阅读本文你将能够知道：</p>
<ol>
<li>统一渲染架构和分离式渲染架构是什么以及二者的区别</li>
<li>固定功能渲染管线和可编程渲染管线是什么以及二者的区别</li>
<li>立即渲染模式和基于TILE的渲染模式是什么以及二者的区别</li>
</ol>
<h1 id="NVIDIA-GPU历史简单介绍"><a href="#NVIDIA-GPU历史简单介绍" class="headerlink" title="NVIDIA GPU历史简单介绍"></a>NVIDIA GPU历史简单介绍</h1><p>NVIDIA在1999年推出GeForce 256时，提出了GPU这个概念。</p>
<p>随后NVIDIA陆续推出了GeForce 2系列、GeForce 3系列、GeForce 4系列、GeForce 5系列、GeForce 6系列、GeForce 7系列和GeForce 8系列的GPU。</p>
<p>在推出GeForce 3系列GPU时，NVIDIA采用了可编程的渲染管线。此前的GPU都是固定功能的渲染管线。</p>
<p>在推出GeForce 8系列GPU时，NVIDIA采用了统一渲染架构。此前的GPU都是分离式渲染架构。</p>
<p>也是在推出GeForce 8系列GPU时，NVIDIA开始给GPU的架构命名。架构名都是以在科学发展历史中做出过突出贡献的人的名字来命名。GeForce 8系列的架构名称为<a href="https://en.wikipedia.org/wiki/Tesla_(microarchitecture)" target="_blank" rel="noopener">Tesla</a>，这是NVIDIA第一个采用统一渲染的架构。</p>
<p>随后NVIDIA又陆续推出了<a href="https://en.wikipedia.org/wiki/Fermi_(microarchitecture)" target="_blank" rel="noopener" title="Fermi (microarchitecture)">Fermi</a>、<a href="https://en.wikipedia.org/wiki/Kepler_(microarchitecture)" target="_blank" rel="noopener" title="Kepler (microarchitecture)">Kepler</a>、<a href="https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)" target="_blank" rel="noopener" title="Maxwell (microarchitecture)">Maxwell</a>、<a href="https://en.wikipedia.org/wiki/Pascal_(microarchitecture)" target="_blank" rel="noopener" title="Pascal (microarchitecture)">Pascal</a>、<a href="https://en.wikipedia.org/wiki/Volta_(microarchitecture)" target="_blank" rel="noopener" title="Volta (microarchitecture)">Volta</a>、<a href="https://en.wikipedia.org/wiki/Turing_(microarchitecture)" target="_blank" rel="noopener" title="Turing (microarchitecture)">Turing</a>、Ampere等架构。</p>
<p>Fermi架构是NVIDIA第一个支持通用计算的架构。</p>
<p>在上面的介绍中出现了一些概念：可编程渲染管线、固定功能渲染管线、统一渲染架构、分离式渲染架构，在下面的章节中将详细介绍这些概念。这里提出来是为了让大家看到这些概念出现的时间顺序：</p>
<ol>
<li>固定功能渲染管线</li>
<li>可编程渲染管线</li>
<li>分离式渲染架构</li>
<li>统一渲染架构</li>
</ol>
<h1 id="固定功能渲染管线和可编程渲染管线"><a href="#固定功能渲染管线和可编程渲染管线" class="headerlink" title="固定功能渲染管线和可编程渲染管线"></a>固定功能渲染管线和可编程渲染管线</h1><p>一开始，GPU设计者想要完成顶点渲染这个功能，那么他会选择一个顶点光照算法，如Phong，然后使用硬件实现该算法。这样做的好处很明显：速度快。但一旦你选择了Phong光照算法，那么这个GPU就只支持这个算法，因为GPU的硬件已经固定死了。即使出现了一个更好的光照算法，你也无法更新。这个时候的GPU几乎所有的算法都是硬件加速实现，更准确地说，是把硬件加速的图形算法单元整合在一起组成一个GPU。</p>
<p>然后，可编程渲染管线应运而生。顶点着色和片段着色是可编程的，着色程序都运行在一个微处理器上。通常，这个微处理器被称为Shader Core。用户可以通过编写不同的染色程序自定义图形渲染的效果，这是一件令人兴奋的事情！</p>
<h1 id="分离式渲染架构和统一渲染架构"><a href="#分离式渲染架构和统一渲染架构" class="headerlink" title="分离式渲染架构和统一渲染架构"></a>分离式渲染架构和统一渲染架构</h1><p>由于顶点着色程序对精度要求较高，而片段着色程序要求较低，并且一般情况下，少量的顶点会生成大量的片段，所以GPU设计者设计了两类Shader Core：一类专门处理顶点着色程序，称为顶点着色器；另一类专门处理片段着色程序，称为片段着色器。并且顶点着色器的数量少于片段着色器的数量。这便是分离式渲染：顶点着色和片段着色在各自专门的硬件单元中进行。</p>
<p>慢慢地会发现，处理小三角形比较多的场景时，顶点着色器利用率很高，而部分片段着色器空闲；处理大三角形比较多的场景或者渲染纹理较多的场景时，顶点着色器部分空闲，而片段着色器利用率很高。</p>
<p>那是不是可以设计一个Shader Core，它既可以做顶点着色，也可以做片段着色以提高硬件资源的利用率？答案是肯定的。</p>
<p>统一渲染由此诞生！</p>
<p>基于统一渲染架构，Shader Core被挖掘出了更多的使用方法，比如通用计算。如果GPU被用来做通用计算，那么GPU中的图形算法硬件加速器（比如光栅化）是不工作的。</p>
<h1 id="立即渲染模式和基于TILE的渲染模式"><a href="#立即渲染模式和基于TILE的渲染模式" class="headerlink" title="立即渲染模式和基于TILE的渲染模式"></a>立即渲染模式和基于TILE的渲染模式</h1><p>芯片架构通常要考虑三个核心要素：功耗、性能和面积。我们可以简记为PPA（Power、Performance、Area）</p>
<p>一个好的GPU架构需要针对GPU产品的应用场景，在PPA组成的三角形中选择一个好的平衡点。比如移动端的GPU更加注重功耗和面积，而桌面端的GPU更加注重性能。</p>
<p>立即渲染模式的GPU侧重于性能，而基于TILE的渲染模式的GPU侧重于功耗。因此，前者常见于桌面级GPU，而后者常见于移动端GPU。</p>
<p>二者的详细介绍，请参看我的另一篇博客《基于TILE的渲染》。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>如果顶点/片段着色算法是使用固定的硬件加速器实现，那么该GPU采用的就是固定功能的渲染管线；如果顶点/片段着色算法是可编程替换的，那么该GPU采用的就是可编程的渲染管线。</li>
<li>如果GPU中存在两种类型的Shader Core，一种只能运行顶点着色程序，另一种只能运行片段着色程序，那么该GPU就是分离式渲染架构；如果GPU中的所有Shader Core既可以运行顶点着色程序，也可以运行片段着色程序，那么该GPU就是统一渲染架构。</li>
<li>如果GPU渲染逻辑中，顶层遍历元素是图元，那么该GPU采用的是立即渲染模式；如果GPU渲染逻辑中，顶层遍历元素是TILE，那么该GPU采用的是基于TILE的渲染模式。</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/Unified_shader_model" target="_blank" rel="noopener">Unified Shader Model</a></li>
<li><a href="https://www.imgtec.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/" target="_blank" rel="noopener">A look at the PowerVR graphics architecture: Tile-based rendering</a></li>
<li><a href="https://community.arm.com/developer/tools-software/graphics/b/blog/posts/the-mali-gpu-an-abstract-machine-part-2---tile-based-rendering" target="_blank" rel="noopener">The Mali GPU: An Abstract Machine, Part 2 - Tile-based Rendering</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/12/23/gpu_terms/" data-id="ck63782n8000d09wwh2q76vdt" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/IMR/" rel="tag">IMR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" rel="tag">分离式渲染</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">可编程渲染管线</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">固定功能渲染管线</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" rel="tag">统一渲染</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tbr" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/22/tbr/" class="article-date">
  <time datetime="2019-12-22T00:00:00.000Z" itemprop="datePublished">2019-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/22/tbr/">基于TILE的渲染</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="缩写"><a href="#缩写" class="headerlink" title="缩写"></a>缩写</h1><table>
<thead>
<tr>
<th>缩写</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>GPU</td>
<td>Graphics Processing Unit，图形处理单元。</td>
</tr>
<tr>
<td>SC</td>
<td>Shader Core，渲染核。GPU中的微处理器，负责执行顶点着色程序、片段着色程序和通用计算程序。</td>
</tr>
<tr>
<td>TBR</td>
<td>Tile-based Rendering，基于TILE的渲染。</td>
</tr>
<tr>
<td>IMR</td>
<td>Immediate Mode Rendering，立即渲染模式。</td>
</tr>
</tbody></table>
<h1 id="TILE"><a href="#TILE" class="headerlink" title="TILE"></a>TILE</h1><p>TILE的必应词典翻译是：地砖、瓦片。在这里，TILE是指将整个屏幕分成若干个小格。</p>
<p>TBR是将渲染一屏图像变换为渲染屏幕中的所有TILE。GPU中的一个SC渲染一个TILE，所以GPU中的SC越多，并行渲染TILE的能力就越强。</p>
<p>我们知道，屏幕显示的内容是帧缓冲区中的所有像素颜色，实际上，除了颜色之外，还有像素的深度和模板也会存储在显存中。</p>
<p>将整个屏幕划分成若干个TILE意味着，将颜色、深度、模板缓冲区划分成若干个小的存储。</p>
<h2 id="TILE的大小"><a href="#TILE的大小" class="headerlink" title="TILE的大小"></a>TILE的大小</h2><p>一般来说，TILE的大小为32x32或者16x16。有的情况下，TILE还可以是矩形。</p>
<p>总之，TILE的大小一般都不大。</p>
<p>TILE足够小则意味着这个TILE对应的颜色、深度、模板缓冲区的存储在片上也可以放一份。这样做有什么好处呢？</p>
<h2 id="TILE的好处"><a href="#TILE的好处" class="headerlink" title="TILE的好处"></a>TILE的好处</h2><p>假设GPU当前渲染的帧中包含100个三角形，且开启了深度模板测试和混合，那么，传统的渲染模式（立即渲染模式，IMR）每渲染一个三角形就需要从显存中读取这个三角形所覆盖的所有像素的颜色、深度和模板，渲染之后还需要立马写回显存。</p>
<p>耗时耗力！</p>
<img src="/2019/12/22/tbr/imr_data_flow.png" class="" title="立即渲染数据流">

<p>而TBR会逐个遍历TILE，首先看都有哪些三角形覆盖了当前遍历到的TILE，最坏的情况下，某个TILE被100个三角形所覆盖，那么遍历这100个三角形，每渲染一个三角形(TILE覆盖部分而非三角形全部)则将结果放到这个TILE对应的片上高速缓存中，直到遍历完所有的三角形，最后将结果写回显存中的帧缓冲区。</p>
<p>可以看到，TBR将读写显存的频率大大降低。这首先带来的好处是低功耗，其次是高效率。</p>
<img src="/2019/12/22/tbr/tbr_data_flow.png" class="" title="分块渲染数据流">

<p>除此之外，TILE还可以提高多采样的效率，方便应用一些优化策略。</p>
<h1 id="TBR"><a href="#TBR" class="headerlink" title="TBR"></a>TBR</h1><p>TBR的处理逻辑是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> tile : tiles) &#123;</span><br><span class="line">    <span class="keyword">auto</span> primitives = tile.getPrimitiveList();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> primitive : primitives) &#123;</span><br><span class="line">        <span class="keyword">auto</span> fragments = primitive.getFragmentsInTile(tile);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> fragment : fragments) &#123;</span><br><span class="line">            fragment.render();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而IMR的处理逻辑是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> drawcall : drawcalls) &#123;</span><br><span class="line">    <span class="keyword">auto</span> primitives = drawcall.getPrimitives();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> primitive : primitives) &#123;</span><br><span class="line">        <span class="keyword">auto</span> fragments = primitive.getFragments();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> fragment : fragments) &#123;</span><br><span class="line">            fragment.render();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到TBR处理逻辑的第二行有一个操作是：<code>tile.getPrimitiveList</code>，这个操作是为了获取当前帧中覆盖了这个TILE的所有图元。</p>
<p>假设当前帧中有100个三角形，当第一个三角形所覆盖的TILE全部统计好了，也不能<code>立即渲染</code>，而需要等这100个三角形的覆盖情况都统计完成才能开始遍历TILE。这是因为如果直接开始遍历就和IMR的逻辑是一样的了，失去了TBR的优势。遍历TILE的前提便是每个TILE要能够完整表示屏幕中的一小部分，如果当前TILE中的内容还没准备好就直接开始渲染，其渲染结果虽然也可以放在片上，但是你不知道何时将片上存储的内容写回显存。</p>
<p>使用TBR渲染模式的GPU，通常会将染色好的顶点写回显存，然后再读出来将其构建成图元，根据图元的覆盖情况构建每个TILE的图元列表，图元列表也会被写回显存。一帧的所有TILE的图元列表构建完成后，再让SC读取出为其分配的TILE的图元列表。而采用IMR渲染模式的GPU是没有读写图元列表操作的。</p>
<p>虽然TBR多了读写图元列表的操作，但是相比于节省下来的读写缓冲区的操作，还是很划算的。</p>
<h1 id="TBDR"><a href="#TBDR" class="headerlink" title="TBDR"></a>TBDR</h1><p>由于要绘制的场景中存在大量的遮挡情况，而被遮挡的片段也是花费了很多时间和资源才计算出它们的位置和颜色，但最终我们看不到（最终的图像不会包含这些像素点的信息），所以，这部分工作就属于无用功。</p>
<p>TBDR（Tile Based Deferred Rendering）的核心思想是在确定好每个像素是否会最终显示到屏幕上之后，才开始渲染那些会显示到屏幕上的像素。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.imgtec.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/" target="_blank" rel="noopener">A look at the PowerVR graphics architecture: Tile-based rendering</a></li>
<li><a href="https://community.arm.com/developer/tools-software/graphics/b/blog/posts/the-mali-gpu-an-abstract-machine-part-2---tile-based-rendering" target="_blank" rel="noopener">The Mali GPU: An Abstract Machine, Part 2 - Tile-based Rendering</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/12/22/tbr/" data-id="ck63782nb000h09ww1yb1auis" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GLSLCompilerPhases" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/13/GLSLCompilerPhases/" class="article-date">
  <time datetime="2019-11-13T00:00:00.000Z" itemprop="datePublished">2019-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/13/GLSLCompilerPhases/">GLSL 编译器处理逻辑</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="GLSL介绍"><a href="#GLSL介绍" class="headerlink" title="GLSL介绍"></a>GLSL介绍</h1><p>GLSL是多种紧密相关的语言，这些语言用于为OpenGL API处理管道中包含的每个可编程处理器创建着色器。包含如下的着色器：</p>
<ul>
<li>Vertex</li>
<li>Tessellation Control</li>
<li>Tessellation Evalution</li>
<li>Geometry</li>
<li>Fragment</li>
<li>Compute</li>
</ul>
<h1 id="编译器处理阶段"><a href="#编译器处理阶段" class="headerlink" title="编译器处理阶段"></a>编译器处理阶段</h1><p>Shader处理器的编译单元在编译的最后阶段可选地链接在一起之前被分别处理。其处理逻辑如下：</p>
<ol>
<li>源字符串是以字节序列输入，’\0’被解释为终止符。</li>
<li>所有源字符串被串联以形成单个输入，’\0’字节被丢弃，所有其他值均保留。(每个shader可能有多个输入字符串)</li>
<li>每个字符串均根据UTF-8标准进行解释，不同之处在于，所有无效字节序列均以其原始形式保留以用于后续处理。</li>
<li>每个{回车，换行}和{换行，回车}序列都由单个换行符代替，所有剩余的回车符和换行符都将用单个换行符替代。</li>
<li>每个字符的行号等于前一个换行符的数量加一。请注意，此操作只能随后通过#line指令进行更改，并且不受编译阶段6中删除换行符的影响。</li>
<li>在换行符之前出现反斜杠（’&#39;）的都将被删除（转义）。请注意，不会替换任何空格，从而允许单个预处理令牌跨越换行符。此操作不是递归的；不会删除任何新生成的{反斜杠 换行符}序列。</li>
<li>所有注释均替换为一个空格。注释中允许所有（非零）字符和无效的UTF-8字节序列。’//‘样式注释包括初始的’//‘标记，并一直延续到但不包括终止换行符。’/…/‘注释同时包含开始和结束标记。</li>
<li>源字符串将转换为一系列预处理Token。这些Token包括预处理编号，标识符和预处理操作。每一个Token的行号是Token开始的第一个字节的行号。</li>
<li>预处理器运行。执行指令并执行宏扩展。</li>
<li>空格和换行符将被丢弃。</li>
<li>预处理Token将转换为Token</li>
<li>语法根据GLSL ES语法进行分析。</li>
<li>根据语言的语义规则检查结果。</li>
<li>将着色器链接在一起以形成一个或多个程序或分离的程序。当将一对连续阶段的着色器链接到同一程序时，两个着色器中未使用的任何输出和相应的输入都可能会被丢弃。</li>
<li>生成二进制文件。</li>
</ol>
<p>From：<a href="https://www.khronos.org/registry/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.html#logical-phases-of-compilation" target="_blank" rel="noopener">https://www.khronos.org/registry/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.html#logical-phases-of-compilation</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/11/13/GLSLCompilerPhases/" data-id="ck63782n1000809ww5u0k9ke9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GLSL/" rel="tag">GLSL</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-fermi" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/11/fermi/" class="article-date">
  <time datetime="2019-11-11T00:00:00.000Z" itemprop="datePublished">2019-11-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/11/fermi/">Fermi架构介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Fermi是NVIDIA公司的GPU架构的名称。取这个名字是为了纪念美籍著名意大利物理学家Erico Fermi。</p>
<p>Erico Fermi造出了人类第一台可控核反应堆—芝加哥一号堆，被称为“原子能之父”，在1938年获得了诺贝尔物理学奖。</p>
<p>NVIDIA声称Fermi架构是世界上第一个完整地支持通用计算的GPU架构。</p>
<h1 id="架构模型"><a href="#架构模型" class="headerlink" title="架构模型"></a>架构模型</h1><img src="/2019/11/11/fermi/fermi-0.png" class="" title="Fermi结构">
<img src="/2019/11/11/fermi/fermi-1.png" class="" title="SM结构">
<img src="/2019/11/11/fermi/fermi-2.png" class="" title="SM执行Warp指令">

<h1 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h1><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Application可以包含一个或多个<a href="#Kernel">Kernel</a>，通常用来做顶点/像素染色或者通用计算。与常见的CPU程序相比，Application的分支跳转语句相对较少；程序长度相对较短；算数运算类语句相对较多。</p>
<p>Application支持OpenGL、CUDA、OpenCL和Direct Compute API。</p>
<h2 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h2><p>一个<a href="#Grid">Grid</a>执行一个Kernel。这是CUDA和OpenCL中的概念，意指计算算法单元。需要注意的是它和操作系统中的内核不是同一个概念。</p>
<p>Kernel在C语言的基础上扩展了并行运算的语法，以取代串行的循环等语句。除此之外，它还支持C++、Fortran、Java、MATLAB和Python。</p>
<h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a>Grid</h2><p>Grid可以包含一个或多个<a href="#ThreadBlock">ThreadBlock</a>。与Kernel是一一对应的关系。</p>
<h2 id="ThreadBlock"><a href="#ThreadBlock" class="headerlink" title="ThreadBlock"></a>ThreadBlock</h2><p>ThreadBlock可以包含最多48个<a href="#Warp">Warp</a>，也就是1536个<a href="线程">线程</a>。一个ThreadBlock里面的所有线程都运行在同一个SM上，他们之间可以协作和共享存储。</p>
<h2 id="Warp"><a href="#Warp" class="headerlink" title="Warp"></a>Warp</h2><p>一个Warp包含32个<a href="#Thread">Thread</a>，不同ThreadBlock中的Warp可以并行执行。Warp是SM中的基本调度单元。</p>
<h2 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h2><p>多个Thread可以并行执行，Fermi采用SIMT（Single Instruction Multiple Threads）架构。Warp可以快速切换，这是因为每个线程都有自己独立的寄存器和私有存储，Warp切换时不需要数据搬运。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/11/11/fermi/" data-id="ck63782n3000909ww1xjd0qzt" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Fermi/" rel="tag">Fermi</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpgpusim_install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/23/gpgpusim_install/" class="article-date">
  <time datetime="2019-10-23T14:17:50.000Z" itemprop="datePublished">2019-10-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/23/gpgpusim_install/">GPGPU-Sim 安装过程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>GPU英文名称为Graphic Processing Unit，中文名称为图形处理器，主要用于计算机系统中的显示及图形处理，又称为Video Card(显卡)。</p>
<p>GPU具有一下特性：</p>
<ul>
<li>针对高度并行的工作负载进行优化</li>
<li>高度可编程性</li>
<li>桌面级的超级计算机</li>
</ul>
<h2 id="GPGPU"><a href="#GPGPU" class="headerlink" title="GPGPU"></a>GPGPU</h2><p>异构计算（Heterogeneous Computing）是指在异构计算系统上进行的并行计算。<br>GPGPU（General-purpose computing on graphics processing units）是一种利用处理图形任务的图形处理器来计算原本由中央处理器处理的通用计算任务。</p>


<h2 id="GPGPU-Sim"><a href="#GPGPU-Sim" class="headerlink" title="GPGPU-Sim"></a>GPGPU-Sim</h2><p>GPGPU-Sim 是一个时钟级别的GPU仿真模型，可以运行使用cuda或者OpenCL编写的GPU计算程序。GPGPU的github如下：<br><a href="https://github.com/gpgpu-sim/gpgpu-sim_distribution" target="_blank" rel="noopener">https://github.com/gpgpu-sim/gpgpu-sim_distribution</a></p>
<h1 id="安装-GPGPU-Sim"><a href="#安装-GPGPU-Sim" class="headerlink" title="安装 GPGPU Sim"></a>安装 GPGPU Sim</h1><p>本文介绍在虚拟机Centos7上配置安装GPGPU sim环境。<br>需要准备环境：</p>
<ul>
<li>Linux 环境：Centos 7</li>
<li>Cuda环境：Cuda Toolkit 7.5 <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a></li>
<li>GPGPU sim：<a href="https://github.com/gpgpu-sim/gpgpu-sim_distribution" target="_blank" rel="noopener">https://github.com/gpgpu-sim/gpgpu-sim_distribution</a> （branch: dev）</li>
</ul>
<h2 id="安装Cuda"><a href="#安装Cuda" class="headerlink" title="安装Cuda"></a>安装Cuda</h2><p>GPGPU-Sim支持的Cuda版本有：4.2, 5.0, 5.5, 6.0, 7.5, 8.0, 9.0, 9.1。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum localinstall cuda-repo-rhel7-7.5-18.x86_64.rpm</span><br><span class="line">yum install cuda-tooklit-7-5</span><br></pre></td></tr></table></figure>
<h2 id="编译安装GPGPU-Sim"><a href="#编译安装GPGPU-Sim" class="headerlink" title="编译安装GPGPU-Sim"></a>编译安装GPGPU-Sim</h2><h3 id="安装依赖库"><a href="#安装依赖库" class="headerlink" title="安装依赖库"></a>安装依赖库</h3><p>安装依赖:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># GPGPU-Sim dependencies:</span><br><span class="line">yum install gcc</span><br><span class="line">yum install gcc-c++</span><br><span class="line">yum install make</span><br><span class="line">yum install makedepend</span><br><span class="line">yum install xorg-x11-utils</span><br><span class="line">yum install bison</span><br><span class="line">yum install flex</span><br><span class="line">yum install zlib</span><br><span class="line"></span><br><span class="line"># GPGPU-Sim documentation dependencies:</span><br><span class="line">yum install doxygen</span><br><span class="line">yum install graphviz</span><br><span class="line"></span><br><span class="line"># AerialVision dependencies:</span><br><span class="line">yum install python-pmw</span><br><span class="line">yum install python-ply</span><br><span class="line">yum install python2-numpy</span><br><span class="line">yum install libpng12-devel</span><br><span class="line">yum install python-matplotlib</span><br></pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>编译前需要设置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_INSTALL_PATH=/usr/local/cuda</span><br><span class="line">export PATH=$&#123;CUDA_INSTALL_PATH&#125;/bin:$&#123;PATH&#125;</span><br><span class="line">source setup_environment</span><br></pre></td></tr></table></figure>
<p>之后可以直接使用make进行编译：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8</span><br></pre></td></tr></table></figure>
<h2 id="运行demo"><a href="#运行demo" class="headerlink" title="运行demo"></a>运行demo</h2><p>cuda的helloworld程序如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/* file: hello.cu */</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;cuda_runtime.h&gt;</span><br><span class="line"></span><br><span class="line">__global__ void add(int a, int b, int *c)</span><br><span class="line">&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    int c;</span><br><span class="line">    int *dev_c;</span><br><span class="line">    cudaMalloc((void **)&amp;dev_c, sizeof(int));</span><br><span class="line">    add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);</span><br><span class="line">    cudaMemcpy(&amp;c, &amp;dev_c, sizeof(int), cudaMemcpyDeviceToHost);</span><br><span class="line">    printf(&quot;2 + 7 = %d\n&quot;, c);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译程序时指定<code>--cudart shared</code>确保可执行程序动态链接到CUDA runtime库。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --cudart shared -o hello hello.cu</span><br></pre></td></tr></table></figure>
<p>上文2.2.2中通过<code>source setup_environment</code>设置可执行程序连接到GPGPU-Sim编译的libcudart.so中。<br>运行ldd确保链接正确的libcudart.so:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldd hello</span><br></pre></td></tr></table></figure>
<p>运行程序之前需要拷贝GPGPU-Sim路径下的<code>configs/tested-cfgs/SM2_GTX480/</code>的配置文件到当前运行demo的路径下。<br>最后运行编译的可执行程序即可正常仿真:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hello</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/2019/10/23/gpgpusim_install/" data-id="ck63782n5000b09ww65zw45b2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPGPU-Sim/" rel="tag">GPGPU-Sim</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CPU/" rel="tag">CPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fermi/" rel="tag">Fermi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GLSL/" rel="tag">GLSL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPGPU-Sim/" rel="tag">GPGPU-Sim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IMR/" rel="tag">IMR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vulkan/" rel="tag">Vulkan</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" rel="tag">分离式渲染</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">可编程渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">固定功能渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%BD%A2%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">图形渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" rel="tag">统一渲染</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CPU/" style="font-size: 10px;">CPU</a> <a href="/tags/Fermi/" style="font-size: 10px;">Fermi</a> <a href="/tags/GLSL/" style="font-size: 10px;">GLSL</a> <a href="/tags/GPGPU-Sim/" style="font-size: 10px;">GPGPU-Sim</a> <a href="/tags/GPU/" style="font-size: 20px;">GPU</a> <a href="/tags/IMR/" style="font-size: 10px;">IMR</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/TBR/" style="font-size: 15px;">TBR</a> <a href="/tags/Vulkan/" style="font-size: 10px;">Vulkan</a> <a href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">分离式渲染</a> <a href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">可编程渲染管线</a> <a href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">固定功能渲染管线</a> <a href="/tags/%E5%9B%BE%E5%BD%A2%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">图形渲染管线</a> <a href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">统一渲染</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/30/rendering_pipeline/">图形渲染管线</a>
          </li>
        
          <li>
            <a href="/2019/12/29/gpu_vs_cpu/">CPU和GPU的区别</a>
          </li>
        
          <li>
            <a href="/2019/12/28/vulkan_study_plan/">Vulkan学习计划</a>
          </li>
        
          <li>
            <a href="/2019/12/26/gpu_performance/">GPU性能指标</a>
          </li>
        
          <li>
            <a href="/2019/12/23/gpu_terms/">GPU的渲染架构、渲染管线和渲染模式分类</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 GPU Insight<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>