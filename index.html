<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>GPU 观察</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="GPU 观察">
<meta property="og:url" content="https:&#x2F;&#x2F;gpu-insight.github.io&#x2F;index.html">
<meta property="og:site_name" content="GPU 观察">
<meta property="og:locale" content="cn">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="GPU 观察" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">GPU 观察</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://gpu-insight.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-gpu_performance" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/26/gpu_performance/" class="article-date">
  <time datetime="2019-12-26T00:00:00.000Z" itemprop="datePublished">2019-12-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/26/gpu_performance/">GPU性能指标</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过阅读本文，你将知道GPU的性能指标都有哪些以及他们是如何计算出来的。</p>
<h1 id="GPU性能指标"><a href="#GPU性能指标" class="headerlink" title="GPU性能指标"></a>GPU性能指标</h1><p>在GPU信息数据库-GPU Specs Database，可以查找到几乎所有GPU的信息。GPU信息中有一栏代表的是GPU的性能参数：Theoretical Performance。</p>
<p>通过阅读这一栏数据我们可以知道：</p>
<ol>
<li>这些数据都是<strong>理论上的峰值</strong></li>
<li>性能指标一般有：<strong>纹理填充率</strong>、<strong>像素填充率</strong>和<strong>浮点处理能力</strong></li>
</ol>
<h2 id="理论上的峰值"><a href="#理论上的峰值" class="headerlink" title="理论上的峰值"></a>理论上的峰值</h2><p>所谓理论上的峰值可以理解为理想情况下的峰值，GPU在实际运行过程中几乎都跑不出该峰值。</p>
<p>在得出这个理论上的峰值的过程中，做了很多假设。</p>
<p><strong>假设一，一个时钟完成一次处理。</strong>如：一个时钟完成一个像素的渲染，实际上一个时钟是完不成一个像素的渲染任务的，反而根据我们写的片段染色程序的复杂度，可能需要上百甚至更多的时钟。</p>
<p><strong>假设二，数据已准备好。</strong>如：像素渲染的输入数据总是可以立马获取到，实际并非如此。</p>
<p><strong>假设三，任务调度和逻辑控制不消耗时钟。</strong></p>
<p>至于这个理论上的峰值是如何计算得来的，请参看下面章节的介绍。</p>
<h2 id="纹理填充率"><a href="#纹理填充率" class="headerlink" title="纹理填充率"></a>纹理填充率</h2><blockquote>
<p>纹理填充率 = 纹理单元运行的时钟频率 x 纹理单元的个数 x 每个时钟纹理单元可以处理的纹素个数（理论值）</p>
</blockquote>
<p>比如NAVIDA的<a href="https://www.techpowerup.com/gpu-specs/geforce-gt-430.c603" target="_blank" rel="noopener">GeForce GT 430</a>：</p>
<ul>
<li>纹理单元运行的时钟频率为：700 MHz</li>
<li>纹理单元的个数：16个</li>
<li>每个时钟纹理单元可以处理的纹素个数：1个</li>
</ul>
<p>所以它的纹理填充率为11.20 GTexel/s。</p>
<h2 id="像素填充率"><a href="#像素填充率" class="headerlink" title="像素填充率"></a>像素填充率</h2><blockquote>
<p>像素填充率 = ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数</p>
</blockquote>
<p>比如NAVIDA的<a href="https://www.techpowerup.com/gpu-specs/geforce-gt-430.c603" target="_blank" rel="noopener">GeForce GT 430</a>：</p>
<ul>
<li>ROP运行的时钟频率：700 MHz</li>
<li>ROP的个数：4个</li>
<li>每个时钟ROP可以处理的像素个数：1个</li>
</ul>
<p>所以它的像素填充率为2.800 GPixel/s</p>
<h2 id="浮点处理能力"><a href="#浮点处理能力" class="headerlink" title="浮点处理能力"></a>浮点处理能力</h2><p>浮点处理包含半精度、单精度和双精度浮点的处理。</p>
<p>下面以单精度浮点处理能力为例：</p>
<blockquote>
<p>单精度浮点处理能力 = 渲染核运行的时钟频率 x 渲染核的个数 x 每个渲染核包含的单精度浮点处理单元的个数</p>
</blockquote>
<p>比如NAVIDA的<a href="https://www.techpowerup.com/gpu-specs/geforce-gt-430.c603" target="_blank" rel="noopener">GeForce GT 430</a>：</p>
<ul>
<li>渲染核运行的时钟频率：1400 MHz</li>
<li>渲染核的个数：96个</li>
<li>每个渲染核包含的单精度浮点处理单元的个数：2个（这个数值是逆推出来的，原网页没有该信息）</li>
</ul>
<p>所以它的单精度浮点处理能力为268.8 GFLOPS</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>GPU的性能指标包含：纹理填充率、像素填充率和浮点处理能力</li>
<li>纹理填充率的计算方式为：纹理单元运行的时钟频率 x 纹理单元的个数 x 每个时钟纹理单元可以处理的纹素个数（理论值）</li>
<li>像素填充率的计算方式为：ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数</li>
<li>单精度浮点处理能力的计算方式为：渲染核运行的时钟频率 x 渲染核的个数 x 每个渲染核包含的单精度浮点处理单元的个数</li>
<li>GPU性能指标的数值都是理论值</li>
<li>知道了GPU性能指标的计算方式，我们可以从GPU厂商公布的数据中逆推得到一些有用的信息</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.gpuzoo.com/" target="_blank" rel="noopener">GPUZoo</a></li>
<li><a href="https://www.techpowerup.com/gpu-specs/" target="_blank" rel="noopener">GPU Specs Database</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpu-insight.github.io/2019/12/26/gpu_performance/" data-id="ck4mcph8b000byvkpfqt3dw7g" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpu_terms" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/gpu_terms/" class="article-date">
  <time datetime="2019-12-23T00:00:00.000Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/gpu_terms/">GPU常见概念</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>GPU架构设计中经常会看到诸如：统一渲染vs分离式渲染、固定功能vs可编程、立即渲染vs基于TILE的渲染vs基于TILE的延迟渲染等等。</p>
<p>不管GPU架构按照哪种分类方式都离不开三个要素：功耗、性能和面积。我们可以简记为PPA（Power、Performance、Area）。</p>
<p>一个好的GPU架构需要针对GPU产品的应用场景，在PPA组成的三角形中选择一个好的平衡点。比如移动端的GPU更加注重功耗和面积，而桌面端的GPU更加注重性能。</p>
<p>很早的GPU都采用固定功能的渲染管线。比如想要完成顶点渲染，那么你选择一个顶点光照算法，如Phong，然后使用硬件实现该算法。所谓固定，一旦你选择了Phong光照算法，那你的GPU就只支持这个算法，即使出现了一个更好的光照算法，你也无法更新。</p>
<p>于是，可编程渲染管线出现了。顶点着色和片段着色是可编程的，着色程序都运行在一个微处理器上。我们暂且称这个微处理器为Shader Core。</p>
<p>由于顶点着色程序对精度要求较高，而片段着色程序要求较低，并且一般情况下，少量的顶点会生成大量的片段，所以GPU设计者设计了两类Shader Core：一类专门处理顶点着色程序，称为顶点着色器；另一类专门处理片段着色程序，称为片段着色器。并且顶点着色器的数量少于片段着色器的数量。这便是分离式渲染：顶点着色和片段着色在各自专门的硬件单元中进行。</p>
<p>慢慢地会发现，处理小三角形比较多的场景时，顶点着色器利用率很高，而部分片段着色器空闲；处理大三角形比较多的场景或者渲染纹理较多的场景时，顶点着色器部分空闲，而片段着色器利用率很高。</p>
<p>那是不是可以设计一个Shader Core，它既可以做顶点着色，也可以做片段着色？答案是肯定的。</p>
<p>统一渲染由此诞生。</p>
<p>分离式渲染架构的GPU一般都采用IMR，TBR和TBDR是在统一渲染架构的GPU上衍生出来的。</p>
<p>IMR、TBR和TBDR的介绍请参看<a href="https://www.gpuinsight.com/2019/12/22/tbr/" target="_blank" rel="noopener">《基于TILE的渲染》</a>。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpu-insight.github.io/2019/12/23/gpu_terms/" data-id="ck4mcph8c000cyvkp0oci7v6l" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" rel="tag">分离式渲染</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">可编程渲染管线</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">固定功能渲染管线</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" rel="tag">统一渲染</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tbr" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/22/tbr/" class="article-date">
  <time datetime="2019-12-22T00:00:00.000Z" itemprop="datePublished">2019-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/22/tbr/">基于TILE的渲染</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="缩写"><a href="#缩写" class="headerlink" title="缩写"></a>缩写</h1><table>
<thead>
<tr>
<th>缩写</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>GPU</td>
<td>Graphics Processing Unit，图形处理单元。</td>
</tr>
<tr>
<td>SC</td>
<td>Shader Core，渲染核。GPU中的微处理器，负责执行顶点着色程序、片段着色程序和通用计算程序。</td>
</tr>
<tr>
<td>TBR</td>
<td>Tile-based Rendering，基于TILE的渲染。</td>
</tr>
<tr>
<td>IMR</td>
<td>Immediate Mode Rendering，立即渲染模式。</td>
</tr>
</tbody></table>
<h1 id="TILE"><a href="#TILE" class="headerlink" title="TILE"></a>TILE</h1><p>TILE的必应词典翻译是：地砖、瓦片。在这里，TILE是指将整个屏幕分成若干个小格。</p>
<p>TBR是将渲染一屏图像变换为渲染屏幕中的所有TILE。GPU中的一个SC渲染一个TILE，所以GPU中的SC越多，并行渲染TILE的能力就越强。</p>
<p>我们知道，屏幕显示的内容是帧缓冲区中的所有像素颜色，实际上，除了颜色之外，还有像素的深度和模板也会存储在显存中。</p>
<p>将整个屏幕划分成若干个TILE意味着，将颜色、深度、模板缓冲区划分成若干个小的存储。</p>
<h2 id="TILE的大小"><a href="#TILE的大小" class="headerlink" title="TILE的大小"></a>TILE的大小</h2><p>一般来说，TILE的大小为32x32或者16x16。有的情况下，TILE还可以是矩形。</p>
<p>总之，TILE的大小一般都不大。</p>
<p>TILE足够小则意味着这个TILE对应的颜色、深度、模板缓冲区的存储在片上也可以放一份。这样做有什么好处呢？</p>
<h2 id="TILE的好处"><a href="#TILE的好处" class="headerlink" title="TILE的好处"></a>TILE的好处</h2><p>假设GPU当前渲染的帧中包含100个三角形，且开启了深度模板测试和混合，那么，传统的渲染模式（立即渲染模式，IMR）每渲染一个三角形就需要从显存中读取这个三角形所覆盖的所有像素的颜色、深度和模板，渲染之后还需要立马写回显存。</p>
<p>耗时耗力！</p>
<p>而TBR会逐个遍历TILE，首先看都有哪些三角形覆盖了当前遍历到的TILE，最坏的情况下，某个TILE被100个三角形所覆盖，那么遍历这100个三角形，每渲染一个三角形(TILE覆盖部分而非三角形全部)则将结果放到这个TILE对应的片上高速缓存中，直到遍历完所有的三角形，最后将结果写回显存中的帧缓冲区。</p>
<p>可以看到，TBR将读写显存的频率大大降低。这首先带来的好处是低功耗，其次是高效率。</p>
<h1 id="TBR"><a href="#TBR" class="headerlink" title="TBR"></a>TBR</h1><p>TBR的处理逻辑是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> tile : tiles) &#123;</span><br><span class="line">    <span class="keyword">auto</span> primitives = tile.getPrimitiveList();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> primitive : primitives) &#123;</span><br><span class="line">        <span class="keyword">auto</span> fragments = primitive.getFragmentsInTile(tile);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> fragment : fragments) &#123;</span><br><span class="line">            fragment.render();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而IMR的处理逻辑是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> drawcall : drawcalls) &#123;</span><br><span class="line">    <span class="keyword">auto</span> primitives = drawcall.getPrimitives();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> primitive : primitives) &#123;</span><br><span class="line">        <span class="keyword">auto</span> fragments = primitive.getFragments();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> fragment : fragments) &#123;</span><br><span class="line">            fragment.render();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到TBR处理逻辑的第二行有一个操作是：<code>tile.getPrimitiveList</code>，这个操作是为了获取当前帧中覆盖了这个TILE的所有图元。</p>
<p>假设当前帧中有100个三角形，当第一个三角形所覆盖的TILE全部统计好了，也不能<code>立即渲染</code>，而需要等这100个三角形的覆盖情况都统计完成才能开始遍历TILE。这是因为如果直接开始遍历就和IMR的逻辑是一样的了，失去了TBR的优势。遍历TILE的前提便是每个TILE要能够完整表示屏幕中的一小部分，如果当前TILE中的内容还没准备好就直接开始渲染，其渲染结果虽然也可以放在片上，但是你不知道何时将片上存储的内容写回显存。</p>
<p>使用TBR渲染模式的GPU，通常会将染色好的顶点写回显存，然后再读出来将其构建成图元，根据图元的覆盖情况构建每个TILE的图元列表，图元列表也会被写回显存。一帧的所有TILE的图元列表构建完成后，再让SC读取出为其分配的TILE的图元列表。而采用IMR渲染模式的GPU是没有读写图元列表操作的。</p>
<p>虽然TBR多了读写图元列表的操作，但是相比于节省下来的读写缓冲区的操作，还是很划算的。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.imgtec.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/" target="_blank" rel="noopener">A look at the PowerVR graphics architecture: Tile-based rendering</a></li>
<li><a href="https://community.arm.com/developer/tools-software/graphics/b/blog/posts/the-mali-gpu-an-abstract-machine-part-2---tile-based-rendering" target="_blank" rel="noopener">The Mali GPU: An Abstract Machine, Part 2 - Tile-based Rendering</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpu-insight.github.io/2019/12/22/tbr/" data-id="ck4mcph8d000fyvkp91draydo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GLSLCompilerPhases" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/13/GLSLCompilerPhases/" class="article-date">
  <time datetime="2019-11-13T00:00:00.000Z" itemprop="datePublished">2019-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/13/GLSLCompilerPhases/">GLSL 编译器处理逻辑</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="GLSL介绍"><a href="#GLSL介绍" class="headerlink" title="GLSL介绍"></a>GLSL介绍</h1><p>GLSL是多种紧密相关的语言，这些语言用于为OpenGL API处理管道中包含的每个可编程处理器创建着色器。包含如下的着色器：</p>
<ul>
<li>Vertex</li>
<li>Tessellation Control</li>
<li>Tessellation Evalution</li>
<li>Geometry</li>
<li>Fragment</li>
<li>Compute</li>
</ul>
<h1 id="编译器处理阶段"><a href="#编译器处理阶段" class="headerlink" title="编译器处理阶段"></a>编译器处理阶段</h1><p>Shader处理器的编译单元在编译的最后阶段可选地链接在一起之前被分别处理。其处理逻辑如下：</p>
<ol>
<li>源字符串是以字节序列输入，’\0’被解释为终止符。</li>
<li>所有源字符串被串联以形成单个输入，’\0’字节被丢弃，所有其他值均保留。(每个shader可能有多个输入字符串)</li>
<li>每个字符串均根据UTF-8标准进行解释，不同之处在于，所有无效字节序列均以其原始形式保留以用于后续处理。</li>
<li>每个{回车，换行}和{换行，回车}序列都由单个换行符代替，所有剩余的回车符和换行符都将用单个换行符替代。</li>
<li>每个字符的行号等于前一个换行符的数量加一。请注意，此操作只能随后通过#line指令进行更改，并且不受编译阶段6中删除换行符的影响。</li>
<li>在换行符之前出现反斜杠（’&#39;）的都将被删除（转义）。请注意，不会替换任何空格，从而允许单个预处理令牌跨越换行符。此操作不是递归的；不会删除任何新生成的{反斜杠 换行符}序列。</li>
<li>所有注释均替换为一个空格。注释中允许所有（非零）字符和无效的UTF-8字节序列。’//‘样式注释包括初始的’//‘标记，并一直延续到但不包括终止换行符。’/…/‘注释同时包含开始和结束标记。</li>
<li>源字符串将转换为一系列预处理Token。这些Token包括预处理编号，标识符和预处理操作。每一个Token的行号是Token开始的第一个字节的行号。</li>
<li>预处理器运行。执行指令并执行宏扩展。</li>
<li>空格和换行符将被丢弃。</li>
<li>预处理Token将转换为Token</li>
<li>语法根据GLSL ES语法进行分析。</li>
<li>根据语言的语义规则检查结果。</li>
<li>将着色器链接在一起以形成一个或多个程序或分离的程序。当将一对连续阶段的着色器链接到同一程序时，两个着色器中未使用的任何输出和相应的输入都可能会被丢弃。</li>
<li>生成二进制文件。</li>
</ol>
<p>From：<a href="https://www.khronos.org/registry/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.html#logical-phases-of-compilation" target="_blank" rel="noopener">https://www.khronos.org/registry/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.html#logical-phases-of-compilation</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpu-insight.github.io/2019/11/13/GLSLCompilerPhases/" data-id="ck4mcph850007yvkphtod1f84" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GLSL/" rel="tag">GLSL</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-fermi" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/11/fermi/" class="article-date">
  <time datetime="2019-11-11T00:00:00.000Z" itemprop="datePublished">2019-11-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/11/fermi/">Fermi架构介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Fermi是NVIDIA公司的GPU架构的名称。取这个名字是为了纪念美籍著名意大利物理学家Erico Fermi。</p>
<p>Erico Fermi造出了人类第一台可控核反应堆—芝加哥一号堆，被称为“原子能之父”，在1938年获得了诺贝尔物理学奖。</p>
<p>NVIDIA声称Fermi架构是世界上第一个完整地支持通用计算的GPU架构。</p>
<h1 id="架构模型"><a href="#架构模型" class="headerlink" title="架构模型"></a>架构模型</h1><img src="/2019/11/11/fermi/fermi-0.png" class="" title="Fermi结构">
<img src="/2019/11/11/fermi/fermi-1.png" class="" title="SM结构">
<img src="/2019/11/11/fermi/fermi-2.png" class="" title="SM执行Warp指令">

<h1 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h1><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Application可以包含一个或多个<a href="#Kernel">Kernel</a>，通常用来做顶点/像素染色或者通用计算。与常见的CPU程序相比，Application的分支跳转语句相对较少；程序长度相对较短；算数运算类语句相对较多。</p>
<p>Application支持OpenGL、CUDA、OpenCL和Direct Compute API。</p>
<h2 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h2><p>一个<a href="#Grid">Grid</a>执行一个Kernel。这是CUDA和OpenCL中的概念，意指计算算法单元。需要注意的是它和操作系统中的内核不是同一个概念。</p>
<p>Kernel在C语言的基础上扩展了并行运算的语法，以取代串行的循环等语句。除此之外，它还支持C++、Fortran、Java、MATLAB和Python。</p>
<h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a>Grid</h2><p>Grid可以包含一个或多个<a href="#ThreadBlock">ThreadBlock</a>。与Kernel是一一对应的关系。</p>
<h2 id="ThreadBlock"><a href="#ThreadBlock" class="headerlink" title="ThreadBlock"></a>ThreadBlock</h2><p>ThreadBlock可以包含最多48个<a href="#Warp">Warp</a>，也就是1536个<a href="线程">线程</a>。一个ThreadBlock里面的所有线程都运行在同一个SM上，他们之间可以协作和共享存储。</p>
<h2 id="Warp"><a href="#Warp" class="headerlink" title="Warp"></a>Warp</h2><p>一个Warp包含32个<a href="#Thread">Thread</a>，不同ThreadBlock中的Warp可以并行执行。Warp是SM中的基本调度单元。</p>
<h2 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h2><p>多个Thread可以并行执行，Fermi采用SIMT（Single Instruction Multiple Threads）架构。Warp可以快速切换，这是因为每个线程都有自己独立的寄存器和私有存储，Warp切换时不需要数据搬运。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpu-insight.github.io/2019/11/11/fermi/" data-id="ck4mcph870008yvkpfrxrhkka" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Fermi/" rel="tag">Fermi</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpgpusim_install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/23/gpgpusim_install/" class="article-date">
  <time datetime="2019-10-23T14:17:50.000Z" itemprop="datePublished">2019-10-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/23/gpgpusim_install/">GPGPU-Sim 安装过程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>GPU英文名称为Graphic Processing Unit，中文名称为图形处理器，主要用于计算机系统中的显示及图形处理，又称为Video Card(显卡)。</p>
<p>GPU具有一下特性：</p>
<ul>
<li>针对高度并行的工作负载进行优化</li>
<li>高度可编程性</li>
<li>桌面级的超级计算机</li>
</ul>
<h2 id="GPGPU"><a href="#GPGPU" class="headerlink" title="GPGPU"></a>GPGPU</h2><p>异构计算（Heterogeneous Computing）是指在异构计算系统上进行的并行计算。<br>GPGPU（General-purpose computing on graphics processing units）是一种利用处理图形任务的图形处理器来计算原本由中央处理器处理的通用计算任务。</p>


<h2 id="GPGPU-Sim"><a href="#GPGPU-Sim" class="headerlink" title="GPGPU-Sim"></a>GPGPU-Sim</h2><p>GPGPU-Sim 是一个时钟级别的GPU仿真模型，可以运行使用cuda或者OpenCL编写的GPU计算程序。GPGPU的github如下：<br><a href="https://github.com/gpgpu-sim/gpgpu-sim_distribution" target="_blank" rel="noopener">https://github.com/gpgpu-sim/gpgpu-sim_distribution</a></p>
<h1 id="安装-GPGPU-Sim"><a href="#安装-GPGPU-Sim" class="headerlink" title="安装 GPGPU Sim"></a>安装 GPGPU Sim</h1><p>本文介绍在虚拟机Centos7上配置安装GPGPU sim环境。<br>需要准备环境：</p>
<ul>
<li>Linux 环境：Centos 7</li>
<li>Cuda环境：Cuda Toolkit 7.5 <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a></li>
<li>GPGPU sim：<a href="https://github.com/gpgpu-sim/gpgpu-sim_distribution" target="_blank" rel="noopener">https://github.com/gpgpu-sim/gpgpu-sim_distribution</a> （branch: dev）</li>
</ul>
<h2 id="安装Cuda"><a href="#安装Cuda" class="headerlink" title="安装Cuda"></a>安装Cuda</h2><p>GPGPU-Sim支持的Cuda版本有：4.2, 5.0, 5.5, 6.0, 7.5, 8.0, 9.0, 9.1。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum localinstall cuda-repo-rhel7-7.5-18.x86_64.rpm</span><br><span class="line">yum install cuda-tooklit-7-5</span><br></pre></td></tr></table></figure>
<h2 id="编译安装GPGPU-Sim"><a href="#编译安装GPGPU-Sim" class="headerlink" title="编译安装GPGPU-Sim"></a>编译安装GPGPU-Sim</h2><h3 id="安装依赖库"><a href="#安装依赖库" class="headerlink" title="安装依赖库"></a>安装依赖库</h3><p>安装依赖:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># GPGPU-Sim dependencies:</span><br><span class="line">yum install gcc</span><br><span class="line">yum install gcc-c++</span><br><span class="line">yum install make</span><br><span class="line">yum install makedepend</span><br><span class="line">yum install xorg-x11-utils</span><br><span class="line">yum install bison</span><br><span class="line">yum install flex</span><br><span class="line">yum install zlib</span><br><span class="line"></span><br><span class="line"># GPGPU-Sim documentation dependencies:</span><br><span class="line">yum install doxygen</span><br><span class="line">yum install graphviz</span><br><span class="line"></span><br><span class="line"># AerialVision dependencies:</span><br><span class="line">yum install python-pmw</span><br><span class="line">yum install python-ply</span><br><span class="line">yum install python2-numpy</span><br><span class="line">yum install libpng12-devel</span><br><span class="line">yum install python-matplotlib</span><br></pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>编译前需要设置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_INSTALL_PATH=/usr/local/cuda</span><br><span class="line">export PATH=$&#123;CUDA_INSTALL_PATH&#125;/bin:$&#123;PATH&#125;</span><br><span class="line">source setup_environment</span><br></pre></td></tr></table></figure>
<p>之后可以直接使用make进行编译：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8</span><br></pre></td></tr></table></figure>
<h2 id="运行demo"><a href="#运行demo" class="headerlink" title="运行demo"></a>运行demo</h2><p>cuda的helloworld程序如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/* file: hello.cu */</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;cuda_runtime.h&gt;</span><br><span class="line"></span><br><span class="line">__global__ void add(int a, int b, int *c)</span><br><span class="line">&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    int c;</span><br><span class="line">    int *dev_c;</span><br><span class="line">    cudaMalloc((void **)&amp;dev_c, sizeof(int));</span><br><span class="line">    add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);</span><br><span class="line">    cudaMemcpy(&amp;c, &amp;dev_c, sizeof(int), cudaMemcpyDeviceToHost);</span><br><span class="line">    printf(&quot;2 + 7 = %d\n&quot;, c);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译程序时指定<code>--cudart shared</code>确保可执行程序动态链接到CUDA runtime库。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --cudart shared -o hello hello.cu</span><br></pre></td></tr></table></figure>
<p>上文2.2.2中通过<code>source setup_environment</code>设置可执行程序连接到GPGPU-Sim编译的libcudart.so中。<br>运行ldd确保链接正确的libcudart.so:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldd hello</span><br></pre></td></tr></table></figure>
<p>运行程序之前需要拷贝GPGPU-Sim路径下的<code>configs/tested-cfgs/SM2_GTX480/</code>的配置文件到当前运行demo的路径下。<br>最后运行编译的可执行程序即可正常仿真:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hello</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpu-insight.github.io/2019/10/23/gpgpusim_install/" data-id="ck4mcph89000ayvkp98cp7dxa" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPGPU-Sim/" rel="tag">GPGPU-Sim</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fermi/" rel="tag">Fermi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GLSL/" rel="tag">GLSL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPGPU-Sim/" rel="tag">GPGPU-Sim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" rel="tag">分离式渲染</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">可编程渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">固定功能渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" rel="tag">统一渲染</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Fermi/" style="font-size: 10px;">Fermi</a> <a href="/tags/GLSL/" style="font-size: 10px;">GLSL</a> <a href="/tags/GPGPU-Sim/" style="font-size: 10px;">GPGPU-Sim</a> <a href="/tags/GPU/" style="font-size: 20px;">GPU</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/TBR/" style="font-size: 15px;">TBR</a> <a href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">分离式渲染</a> <a href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">可编程渲染管线</a> <a href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">固定功能渲染管线</a> <a href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">统一渲染</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/26/gpu_performance/">GPU性能指标</a>
          </li>
        
          <li>
            <a href="/2019/12/23/gpu_terms/">GPU常见概念</a>
          </li>
        
          <li>
            <a href="/2019/12/22/tbr/">基于TILE的渲染</a>
          </li>
        
          <li>
            <a href="/2019/11/13/GLSLCompilerPhases/">GLSL 编译器处理逻辑</a>
          </li>
        
          <li>
            <a href="/2019/11/11/fermi/">Fermi架构介绍</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 GPU Insight<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>