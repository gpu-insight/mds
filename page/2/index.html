<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>GPU 观察</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="GPU 观察">
<meta property="og:url" content="https:&#x2F;&#x2F;gpuinsight.com&#x2F;page&#x2F;2&#x2F;index.html">
<meta property="og:site_name" content="GPU 观察">
<meta property="og:locale" content="cn">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="GPU 观察" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">GPU 观察</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://gpuinsight.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-tbr" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/tbr/" class="article-date">
  <time datetime="2019-12-22T00:00:00.000Z" itemprop="datePublished">2019-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/tbr/">基于TILE的渲染</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="缩写"><a href="#缩写" class="headerlink" title="缩写"></a>缩写</h1><table>
<thead>
<tr>
<th>缩写</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>GPU</td>
<td>Graphics Processing Unit，图形处理单元。</td>
</tr>
<tr>
<td>SC</td>
<td>Shader Core，渲染核。GPU中的微处理器，负责执行顶点着色程序、片段着色程序和通用计算程序。</td>
</tr>
<tr>
<td>TBR</td>
<td>Tile-based Rendering，基于TILE的渲染。</td>
</tr>
<tr>
<td>IMR</td>
<td>Immediate Mode Rendering，立即渲染模式。</td>
</tr>
</tbody></table>
<h1 id="TILE"><a href="#TILE" class="headerlink" title="TILE"></a>TILE</h1><p>TILE的必应词典翻译是：地砖、瓦片。在这里，TILE是指将整个屏幕分成若干个小格。</p>
<p>TBR是将渲染一屏图像变换为渲染屏幕中的所有TILE。GPU中的一个SC渲染一个TILE，所以GPU中的SC越多，并行渲染TILE的能力就越强。</p>
<p>我们知道，屏幕显示的内容是帧缓冲区中的所有像素颜色，实际上，除了颜色之外，还有像素的深度和模板也会存储在显存中。</p>
<p>将整个屏幕划分成若干个TILE意味着，将颜色、深度、模板缓冲区划分成若干个小的存储。</p>
<h2 id="TILE的大小"><a href="#TILE的大小" class="headerlink" title="TILE的大小"></a>TILE的大小</h2><p>一般来说，TILE的大小为32x32或者16x16。有的情况下，TILE还可以是矩形。</p>
<p>总之，TILE的大小一般都不大。</p>
<p>TILE足够小则意味着这个TILE对应的颜色、深度、模板缓冲区的存储在片上也可以放一份。这样做有什么好处呢？</p>
<h2 id="TILE的好处"><a href="#TILE的好处" class="headerlink" title="TILE的好处"></a>TILE的好处</h2><p>假设GPU当前渲染的帧中包含100个三角形，且开启了深度模板测试和混合，那么，传统的渲染模式（立即渲染模式，IMR）每渲染一个三角形就需要从显存中读取这个三角形所覆盖的所有像素的颜色、深度和模板，渲染之后还需要立马写回显存。</p>
<p>耗时耗力！</p>
<img src="/tbr/imr_data_flow.png" class="" title="立即渲染数据流">

<p>而TBR会逐个遍历TILE，首先看都有哪些三角形覆盖了当前遍历到的TILE，最坏的情况下，某个TILE被100个三角形所覆盖，那么遍历这100个三角形，每渲染一个三角形(TILE覆盖部分而非三角形全部)则将结果放到这个TILE对应的片上高速缓存中，直到遍历完所有的三角形，最后将结果写回显存中的帧缓冲区。</p>
<p>可以看到，TBR将读写显存的频率大大降低。这首先带来的好处是低功耗，其次是高效率。</p>
<img src="/tbr/tbr_data_flow.png" class="" title="分块渲染数据流">

<p>除此之外，TILE还可以提高多采样的效率，方便应用一些优化策略。</p>
<h1 id="TBR"><a href="#TBR" class="headerlink" title="TBR"></a>TBR</h1><p>TBR的处理逻辑是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> tile : tiles) &#123;</span><br><span class="line">    <span class="keyword">auto</span> primitives = tile.getPrimitiveList();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> primitive : primitives) &#123;</span><br><span class="line">        <span class="keyword">auto</span> fragments = primitive.getFragmentsInTile(tile);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> fragment : fragments) &#123;</span><br><span class="line">            fragment.render();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而IMR的处理逻辑是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> drawcall : drawcalls) &#123;</span><br><span class="line">    <span class="keyword">auto</span> primitives = drawcall.getPrimitives();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> primitive : primitives) &#123;</span><br><span class="line">        <span class="keyword">auto</span> fragments = primitive.getFragments();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> fragment : fragments) &#123;</span><br><span class="line">            fragment.render();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到TBR处理逻辑的第二行有一个操作是：<code>tile.getPrimitiveList</code>，这个操作是为了获取当前帧中覆盖了这个TILE的所有图元。</p>
<p>假设当前帧中有100个三角形，当第一个三角形所覆盖的TILE全部统计好了，也不能<code>立即渲染</code>，而需要等这100个三角形的覆盖情况都统计完成才能开始遍历TILE。这是因为如果直接开始遍历就和IMR的逻辑是一样的了，失去了TBR的优势。遍历TILE的前提便是每个TILE要能够完整表示屏幕中的一小部分，如果当前TILE中的内容还没准备好就直接开始渲染，其渲染结果虽然也可以放在片上，但是你不知道何时将片上存储的内容写回显存。</p>
<p>使用TBR渲染模式的GPU，通常会将染色好的顶点写回显存，然后再读出来将其构建成图元，根据图元的覆盖情况构建每个TILE的图元列表，图元列表也会被写回显存。一帧的所有TILE的图元列表构建完成后，再让SC读取出为其分配的TILE的图元列表。而采用IMR渲染模式的GPU是没有读写图元列表操作的。</p>
<p>虽然TBR多了读写图元列表的操作，但是相比于节省下来的读写缓冲区的操作，还是很划算的。</p>
<h1 id="TBDR"><a href="#TBDR" class="headerlink" title="TBDR"></a>TBDR</h1><p>由于要绘制的场景中存在大量的遮挡情况，而被遮挡的片段也是花费了很多时间和资源才计算出它们的位置和颜色，但最终我们看不到（最终的图像不会包含这些像素点的信息），所以，这部分工作就属于无用功。</p>
<p>TBDR（Tile Based Deferred Rendering）的核心思想是在确定好每个像素是否会最终显示到屏幕上之后，才开始渲染那些会显示到屏幕上的像素。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.imgtec.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/" target="_blank" rel="noopener">A look at the PowerVR graphics architecture: Tile-based rendering</a></li>
<li><a href="https://community.arm.com/developer/tools-software/graphics/b/blog/posts/the-mali-gpu-an-abstract-machine-part-2---tile-based-rendering" target="_blank" rel="noopener">The Mali GPU: An Abstract Machine, Part 2 - Tile-based Rendering</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/tbr/" data-id="ckoiclie3000p11l9c2r1bh39" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GLSLCompilerPhases" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/GLSLCompilerPhases/" class="article-date">
  <time datetime="2019-11-13T00:00:00.000Z" itemprop="datePublished">2019-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/GLSLCompilerPhases/">GLSL 编译器处理逻辑</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="GLSL介绍"><a href="#GLSL介绍" class="headerlink" title="GLSL介绍"></a>GLSL介绍</h1><p>GLSL是多种紧密相关的语言，这些语言用于为OpenGL API处理管道中包含的每个可编程处理器创建着色器。包含如下的着色器：</p>
<ul>
<li>Vertex</li>
<li>Tessellation Control</li>
<li>Tessellation Evalution</li>
<li>Geometry</li>
<li>Fragment</li>
<li>Compute</li>
</ul>
<h1 id="编译器处理阶段"><a href="#编译器处理阶段" class="headerlink" title="编译器处理阶段"></a>编译器处理阶段</h1><p>Shader处理器的编译单元在编译的最后阶段可选地链接在一起之前被分别处理。其处理逻辑如下：</p>
<ol>
<li>源字符串是以字节序列输入，’\0’被解释为终止符。</li>
<li>所有源字符串被串联以形成单个输入，’\0’字节被丢弃，所有其他值均保留。(每个shader可能有多个输入字符串)</li>
<li>每个字符串均根据UTF-8标准进行解释，不同之处在于，所有无效字节序列均以其原始形式保留以用于后续处理。</li>
<li>每个{回车，换行}和{换行，回车}序列都由单个换行符代替，所有剩余的回车符和换行符都将用单个换行符替代。</li>
<li>每个字符的行号等于前一个换行符的数量加一。请注意，此操作只能随后通过#line指令进行更改，并且不受编译阶段6中删除换行符的影响。</li>
<li>在换行符之前出现反斜杠（’&#39;）的都将被删除（转义）。请注意，不会替换任何空格，从而允许单个预处理令牌跨越换行符。此操作不是递归的；不会删除任何新生成的{反斜杠 换行符}序列。</li>
<li>所有注释均替换为一个空格。注释中允许所有（非零）字符和无效的UTF-8字节序列。’//‘样式注释包括初始的’//‘标记，并一直延续到但不包括终止换行符。’/…/‘注释同时包含开始和结束标记。</li>
<li>源字符串将转换为一系列预处理Token。这些Token包括预处理编号，标识符和预处理操作。每一个Token的行号是Token开始的第一个字节的行号。</li>
<li>预处理器运行。执行指令并执行宏扩展。</li>
<li>空格和换行符将被丢弃。</li>
<li>预处理Token将转换为Token</li>
<li>语法根据GLSL ES语法进行分析。</li>
<li>根据语言的语义规则检查结果。</li>
<li>将着色器链接在一起以形成一个或多个程序或分离的程序。当将一对连续阶段的着色器链接到同一程序时，两个着色器中未使用的任何输出和相应的输入都可能会被丢弃。</li>
<li>生成二进制文件。</li>
</ol>
<p>From：<a href="https://www.khronos.org/registry/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.html#logical-phases-of-compilation" target="_blank" rel="noopener">https://www.khronos.org/registry/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.html#logical-phases-of-compilation</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/GLSLCompilerPhases/" data-id="ckoiclidi000811l91kao62rz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GLSL/" rel="tag">GLSL</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-fermi" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/fermi/" class="article-date">
  <time datetime="2019-11-11T00:00:00.000Z" itemprop="datePublished">2019-11-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/fermi/">Fermi架构介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Fermi是NVIDIA公司的GPU架构的名称。取这个名字是为了纪念美籍著名意大利物理学家Erico Fermi。</p>
<p>Erico Fermi造出了人类第一台可控核反应堆—芝加哥一号堆，被称为“原子能之父”，在1938年获得了诺贝尔物理学奖。</p>
<p>NVIDIA声称Fermi架构是世界上第一个完整地支持通用计算的GPU架构。</p>
<h1 id="架构模型"><a href="#架构模型" class="headerlink" title="架构模型"></a>架构模型</h1><img src="/fermi/fermi-0.png" class="" title="Fermi结构">
<img src="/fermi/fermi-1.png" class="" title="SM结构">
<img src="/fermi/fermi-2.png" class="" title="SM执行Warp指令">

<h1 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h1><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Application可以包含一个或多个<a href="#Kernel">Kernel</a>，通常用来做顶点/像素染色或者通用计算。与常见的CPU程序相比，Application的分支跳转语句相对较少；程序长度相对较短；算数运算类语句相对较多。</p>
<p>Application支持OpenGL、CUDA、OpenCL和Direct Compute API。</p>
<h2 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h2><p>一个<a href="#Grid">Grid</a>执行一个Kernel。这是CUDA和OpenCL中的概念，意指计算算法单元。需要注意的是它和操作系统中的内核不是同一个概念。</p>
<p>Kernel在C语言的基础上扩展了并行运算的语法，以取代串行的循环等语句。除此之外，它还支持C++、Fortran、Java、MATLAB和Python。</p>
<h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a>Grid</h2><p>Grid可以包含一个或多个<a href="#ThreadBlock">ThreadBlock</a>。与Kernel是一一对应的关系。</p>
<h2 id="ThreadBlock"><a href="#ThreadBlock" class="headerlink" title="ThreadBlock"></a>ThreadBlock</h2><p>ThreadBlock可以包含最多48个<a href="#Warp">Warp</a>，也就是1536个<a href="线程">线程</a>。一个ThreadBlock里面的所有线程都运行在同一个SM上，他们之间可以协作和共享存储。</p>
<h2 id="Warp"><a href="#Warp" class="headerlink" title="Warp"></a>Warp</h2><p>一个Warp包含32个<a href="#Thread">Thread</a>，不同ThreadBlock中的Warp可以并行执行。Warp是SM中的基本调度单元。</p>
<h2 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h2><p>多个Thread可以并行执行，Fermi采用SIMT（Single Instruction Multiple Threads）架构。Warp可以快速切换，这是因为每个线程都有自己独立的寄存器和私有存储，Warp切换时不需要数据搬运。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/fermi/" data-id="ckoiclids000b11l95f6b6rr6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Fermi/" rel="tag">Fermi</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-gpgpusim_install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/gpgpusim_install/" class="article-date">
  <time datetime="2019-10-23T14:17:50.000Z" itemprop="datePublished">2019-10-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/gpgpusim_install/">GPGPU-Sim 安装过程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>GPU英文名称为Graphic Processing Unit，中文名称为图形处理器，主要用于计算机系统中的显示及图形处理，又称为Video Card(显卡)。</p>
<p>GPU具有一下特性：</p>
<ul>
<li>针对高度并行的工作负载进行优化</li>
<li>高度可编程性</li>
<li>桌面级的超级计算机</li>
</ul>
<h2 id="GPGPU"><a href="#GPGPU" class="headerlink" title="GPGPU"></a>GPGPU</h2><p>异构计算（Heterogeneous Computing）是指在异构计算系统上进行的并行计算。<br>GPGPU（General-purpose computing on graphics processing units）是一种利用处理图形任务的图形处理器来计算原本由中央处理器处理的通用计算任务。</p>


<h2 id="GPGPU-Sim"><a href="#GPGPU-Sim" class="headerlink" title="GPGPU-Sim"></a>GPGPU-Sim</h2><p>GPGPU-Sim 是一个时钟级别的GPU仿真模型，可以运行使用cuda或者OpenCL编写的GPU计算程序。GPGPU的github如下：<br><a href="https://github.com/gpgpu-sim/gpgpu-sim_distribution" target="_blank" rel="noopener">https://github.com/gpgpu-sim/gpgpu-sim_distribution</a></p>
<h1 id="安装-GPGPU-Sim"><a href="#安装-GPGPU-Sim" class="headerlink" title="安装 GPGPU Sim"></a>安装 GPGPU Sim</h1><p>本文介绍在虚拟机Centos7上配置安装GPGPU sim环境。<br>需要准备环境：</p>
<ul>
<li>Linux 环境：Centos 7</li>
<li>Cuda环境：Cuda Toolkit 7.5 <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a></li>
<li>GPGPU sim：<a href="https://github.com/gpgpu-sim/gpgpu-sim_distribution" target="_blank" rel="noopener">https://github.com/gpgpu-sim/gpgpu-sim_distribution</a> （branch: dev）</li>
</ul>
<h2 id="安装Cuda"><a href="#安装Cuda" class="headerlink" title="安装Cuda"></a>安装Cuda</h2><p>GPGPU-Sim支持的Cuda版本有：4.2, 5.0, 5.5, 6.0, 7.5, 8.0, 9.0, 9.1。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum localinstall cuda-repo-rhel7-7.5-18.x86_64.rpm</span><br><span class="line">yum install cuda-tooklit-7-5</span><br></pre></td></tr></table></figure>
<h2 id="编译安装GPGPU-Sim"><a href="#编译安装GPGPU-Sim" class="headerlink" title="编译安装GPGPU-Sim"></a>编译安装GPGPU-Sim</h2><h3 id="安装依赖库"><a href="#安装依赖库" class="headerlink" title="安装依赖库"></a>安装依赖库</h3><p>安装依赖:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># GPGPU-Sim dependencies:</span><br><span class="line">yum install gcc</span><br><span class="line">yum install gcc-c++</span><br><span class="line">yum install make</span><br><span class="line">yum install makedepend</span><br><span class="line">yum install xorg-x11-utils</span><br><span class="line">yum install bison</span><br><span class="line">yum install flex</span><br><span class="line">yum install zlib</span><br><span class="line"></span><br><span class="line"># GPGPU-Sim documentation dependencies:</span><br><span class="line">yum install doxygen</span><br><span class="line">yum install graphviz</span><br><span class="line"></span><br><span class="line"># AerialVision dependencies:</span><br><span class="line">yum install python-pmw</span><br><span class="line">yum install python-ply</span><br><span class="line">yum install python2-numpy</span><br><span class="line">yum install libpng12-devel</span><br><span class="line">yum install python-matplotlib</span><br></pre></td></tr></table></figure>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>编译前需要设置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_INSTALL_PATH=/usr/local/cuda</span><br><span class="line">export PATH=$&#123;CUDA_INSTALL_PATH&#125;/bin:$&#123;PATH&#125;</span><br><span class="line">source setup_environment</span><br></pre></td></tr></table></figure>
<p>之后可以直接使用make进行编译：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8</span><br></pre></td></tr></table></figure>
<h2 id="运行demo"><a href="#运行demo" class="headerlink" title="运行demo"></a>运行demo</h2><p>cuda的helloworld程序如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/* file: hello.cu */</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;cuda_runtime.h&gt;</span><br><span class="line"></span><br><span class="line">__global__ void add(int a, int b, int *c)</span><br><span class="line">&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    int c;</span><br><span class="line">    int *dev_c;</span><br><span class="line">    cudaMalloc((void **)&amp;dev_c, sizeof(int));</span><br><span class="line">    add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);</span><br><span class="line">    cudaMemcpy(&amp;c, &amp;dev_c, sizeof(int), cudaMemcpyDeviceToHost);</span><br><span class="line">    printf(&quot;2 + 7 = %d\n&quot;, c);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译程序时指定<code>--cudart shared</code>确保可执行程序动态链接到CUDA runtime库。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --cudart shared -o hello hello.cu</span><br></pre></td></tr></table></figure>
<p>上文2.2.2中通过<code>source setup_environment</code>设置可执行程序连接到GPGPU-Sim编译的libcudart.so中。<br>运行ldd确保链接正确的libcudart.so:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldd hello</span><br></pre></td></tr></table></figure>
<p>运行程序之前需要拷贝GPGPU-Sim路径下的<code>configs/tested-cfgs/SM2_GTX480/</code>的配置文件到当前运行demo的路径下。<br>最后运行编译的可执行程序即可正常仿真:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hello</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gpuinsight.com/gpgpusim_install/" data-id="ckoiclidv000d11l9azq966zz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPGPU-Sim/" rel="tag">GPGPU-Sim</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CPU/" rel="tag">CPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fermi/" rel="tag">Fermi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GLSL/" rel="tag">GLSL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPGPU-Sim/" rel="tag">GPGPU-Sim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/" rel="tag">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IMR/" rel="tag">IMR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimize/" rel="tag">Optimize</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Performance/" rel="tag">Performance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TBR/" rel="tag">TBR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vulkan/" rel="tag">Vulkan</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Warp/" rel="tag">Warp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" rel="tag">分离式渲染</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">可编程渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">固定功能渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%BD%A2%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" rel="tag">图形渲染管线</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" rel="tag">统一渲染</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CPU/" style="font-size: 10px;">CPU</a> <a href="/tags/Fermi/" style="font-size: 15px;">Fermi</a> <a href="/tags/GLSL/" style="font-size: 10px;">GLSL</a> <a href="/tags/GPGPU-Sim/" style="font-size: 15px;">GPGPU-Sim</a> <a href="/tags/GPU/" style="font-size: 20px;">GPU</a> <a href="/tags/IMR/" style="font-size: 10px;">IMR</a> <a href="/tags/Optimize/" style="font-size: 10px;">Optimize</a> <a href="/tags/Performance/" style="font-size: 10px;">Performance</a> <a href="/tags/TBR/" style="font-size: 15px;">TBR</a> <a href="/tags/Vulkan/" style="font-size: 10px;">Vulkan</a> <a href="/tags/Warp/" style="font-size: 10px;">Warp</a> <a href="/tags/%E5%88%86%E7%A6%BB%E5%BC%8F%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">分离式渲染</a> <a href="/tags/%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">可编程渲染管线</a> <a href="/tags/%E5%9B%BA%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">固定功能渲染管线</a> <a href="/tags/%E5%9B%BE%E5%BD%A2%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/" style="font-size: 10px;">图形渲染管线</a> <a href="/tags/%E7%BB%9F%E4%B8%80%E6%B8%B2%E6%9F%93/" style="font-size: 10px;">统一渲染</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/warp/">Warp</a>
          </li>
        
          <li>
            <a href="/brain_storm_gpu_path/">头脑风暴之如何做自主可控GPU</a>
          </li>
        
          <li>
            <a href="/gpu_optimize/">GPU优化</a>
          </li>
        
          <li>
            <a href="/arm_mali_g76/">Arm发布Mali-G76 GPU</a>
          </li>
        
          <li>
            <a href="/run_cuda_samples_on_gpgpusim/">Running CUDA Samples Based on GPGPU-Sim</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 GPU Insight<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>